Submission ID,Title,Authors,Status,Abstract,Paper Type,QA Slot 1,QA Slot 2,
46,Dominance as an Indicator of Rapport and Learning in Human-Agent Communication,"Amanda Buddemeyer, Xiaoyi Tian and Erin Walker",Non-archival Accept,"Power dynamics in human-human communication can impact rapport-building and learning gains, but little is known about how power impacts human-agent communication.  In this paper, we examine dominance behavior in utterances between middle-school students and a teachable robot as they work through math problems, as coded by Rogers and Farace's Relational Communication Control Coding Scheme (RCCCS).  We hypothesize that relatively dominant students will show increased learning gains, as will students with greater dominance agreement with the robot.  We also hypothesize that gender could be an indicator of differences in dominance behavior.  We present a preliminary analysis of dominance characteristics in some of the transactions between robot and student.  Ultimately, we hope to determine if manipulating the dominance behavior of a learning robot could support learning.",SRW,"Monday July 6, 2020 SRW Session 3A 12:00 UTC+0","Wednesday July 8, 2020 SRW Session 14A 17:00 UTC+0",
79,Transferring Monolingual Model to Low-Resource Language: The Case of Tigrinya,"Abrhalei Frezghi Tela, Abraham Woubie Zewoudie and Ville Hautamäki",Non-archival Accept,"In recent years, transformer models have achieved great success in natural language processing tasks. Most of the current state-of-the-art NLP results are achieved by using monolingual transformer models, where the model is pre-trained using a single language unlabelled text corpus. Then, the model is fine-tuned to the specific downstream task. However, the cost of pre-training a new transformer model is high for most languages. In this work, we propose a novel transfer learning method to adopt a strong source language model, trained from a large monolingual corpus to a low-resource language. Thus, using XLNet language model, we demonstrate competitive performance with mBERT and a pre-trained target language model on the Cross-lingual Sentiment (CLS) dataset and on a new sentiment analysis dataset for low-resourced language Tigrinya. With only 10k examples of the given Tigrinya sentiment analysis dataset, English XLNet has achieved 78.88% F1-Score outperforming BERT and mBERT by 10% and 7%, respectively. More interestingly, fine-tuning (English) XLNet model on the CLS dataset has promising results compared to mBERT and even outperformed mBERT for one dataset of the Japanese language.",SRW,"Monday July 6, 2020 SRW Session 3B 13:00 UTC+0","Wednesday July 8, 2020 SRW Session 12B 9:00 UTC+0",
99,Research Replication Prediction Using Weakly Supervised Learning,"Tianyi Luo, Xingyu Li, Hainan Wang and Yang Liu",Non-archival Accept,"Knowing whether a published research result can be replicated or not is important. Carrying out direct replication of published research incurs high cost. It is therefore desirable to have a machine learning aided automatic prediction of a result's replicability. Such predictions can provide a confidence score for each article which can further provide guidelines for spot-checks. Since we will only have access to a small size of annotated dataset to train a machine predictor, we explore the possibility of using weakly supervised learning approaches to improve the prediction accuracy of research replication using both labelled and unlabelled datasets based on text information of research papers. Our experiments over real-world datasets show that much better prediction performance can be obtained compared to the supervised models utilizing only a small size of labelled dataset.",SRW,"Monday July 6, 2020 SRW Session 4A 17:00 UTC+0","Tuesday July 7, 2020 SRW Session 8B 13:00 UTC+0",
105,A Geometry-Inspired Attack for Generating Natural Language Adversarial Examples,Zhao Meng and Roger Wattenhofer,Non-archival Accept,"Generating adversarial examples for natural language is hard, as natural language consists of discrete symbols and examples are often of variable lengths. In this paper, we propose a geometry-inspired attack for generating natural language adversarial examples. Our attack generates adversarial examples by iteratively approximating the decision boundary of deep neural networks. Experiments on two datasets with two different models show that our attack fools the models with high success rates, while only replacing a few words. Human evaluation shows that adversarial examples generated by our attack are hard for humans to recognize. Further experiments show that adversarial training can improve model robustness against our attack.",SRW,"Monday July 6, 2020 SRW Session 4B 18:00 UTC+0","Wednesday July 8, 2020 SRW Session 14B 18:00 UTC+0",
115,Self-Attention is Not Only a Weight: Analyzing BERT with Vector Norms,"Goro Kobayashi, Tatsuki Kuribayashi, Sho Yokoi and Kentaro Inui",Non-archival Accept,"Self-attention modules are essential building blocks of Transformer-based language models and hence are the subject of a large number of studies aiming to discover which linguistic capabilities these models possess (Rogers et al., 2020). Such studies are commonly conducted by analyzing correlations of attention weights with specific linguistic phenomena. In this paper, we show that attention weights alone are only one of two factors determining the output of self-attention modules and propose to incorporate the other factor, namely the norm of the transformed input vectors, into the analysis, as well. Our analysis of self-attention modules in BERT (Devlin et al., 2019) shows that the proposed method produces insights that better agree with linguistic intuitions than an analysis based on attention-weights alone. Our analysis further reveals that BERT controls the amount of the contribution from frequent informative and less informative tokens not by attention weights but via vector norms.",SRW,"Tuesday July 7, 2020 SRW Session 6A 5:00 UTC+0","Wednesday July 8, 2020 SRW Session 12B 9:00 UTC+0",
116,Noise-Based Augmentation Techniques for Emotion Datasets: What do we Recommend?,Mimansa Jaiswal and Emily Mower Provost,Non-archival Accept,"Emotion recognition systems are widely used for  many  downstream  applications  such  as mental  health  monitoring,  educational  problems diagnosis, hate speech classification and targeted  advertising.   Yet,  these  systems  are generally   trained   on   audio   or   multimodal datasets collected in a laboratory environment.While acoustically different, they are generally free  of  major  environmental  noises.   The  result  is  that  systems  trained  on  these  datasets falter  when  presented  with  noisy  data,  even when that noise doesn’t affect the human perception of emotions. In this work, we use multiple categories of environmental and synthetic noises to generate black box adversarial examples and use these noises to modify the samples  in  the  IEMOCAP  dataset.   We  evaluate how both human and machine emotion perception  changes  when  noise  is  introduced.   We find that the trained state-of-the-art models fail to classify even moderately noisy samples that humans usually have no trouble comprehend-ing, demonstrating the brittleness of these systems in real world conditions.",SRW,"Monday July 6, 2020 SRW Session 4B 18:00 UTC+0","Wednesday July 8, 2020 SRW Session 13B 13:00 UTC+0",