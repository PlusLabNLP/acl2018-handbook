SubmissionNumber#=%=#129
FinalPaperTitle#=%=#Building a Japanese Typo Dataset from Wikipedia's Revision History
ShortPaperTitle#=%=#
NumberOfPages#=%=#7
CopyrightSigned#=%=#Yu Tanaka
JobTitle#==#
Organization#==#Kyoto University: Yoshida-honmachi, Sakyo-ku, Kyoto, Japan
Abstract#==#User generated texts contain many typos for which correction is necessary for NLP systems to work. Although a large number of typo–correction pairs are needed to develop a data-driven typo correction system, no such dataset is available for Japanese. In this paper, we extract over half a million Japanese typo–correction pairs from Wikipedia’s revision history. Unlike other languages, Japanese poses unique challenges: (1) Japanese texts are unsegmented so that we cannot simply apply a spelling checker, and (2) the way people inputting kanji logographs results in typos with drastically different surface forms from correct ones. We address them by combining character-based extraction rules, morphological analyzers to guess readings, and various filtering methods. We evaluate the dataset using crowdsourcing and run a baseline seq2seq model for typo correction.
Author{1}{Firstname}#=%=#Yu
Author{1}{Lastname}#=%=#Tanaka
Author{1}{Username}#=%=#ytanaka
Author{1}{Email}#=%=#yuu19952006@gmail.com
Author{1}{Affiliation}#=%=#Kyoto University
Author{2}{Firstname}#=%=#Yugo
Author{2}{Lastname}#=%=#Murawaki
Author{2}{Username}#=%=#murawaki
Author{2}{Email}#=%=#murawaki@gmail.com
Author{2}{Affiliation}#=%=#Kyoto University
Author{3}{Firstname}#=%=#Daisuke
Author{3}{Lastname}#=%=#Kawahara
Author{3}{Username}#=%=#dk
Author{3}{Email}#=%=#dkw@waseda.jp
Author{3}{Affiliation}#=%=#Waseda University
Author{4}{Firstname}#=%=#Sadao
Author{4}{Lastname}#=%=#Kurohashi
Author{4}{Username}#=%=#kuro
Author{4}{Email}#=%=#kuro@i.kyoto-u.ac.jp
Author{4}{Affiliation}#=%=#Kyoto University

==========