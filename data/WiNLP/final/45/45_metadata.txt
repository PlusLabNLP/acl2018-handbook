SubmissionNumber#=%=#45
FinalPaperTitle#=%=#Defining and Evaluating Fair Natural Language Generation
ShortPaperTitle#=%=#
NumberOfPages#=%=#3
CopyrightSigned#=%=#Catherine Yeo
JobTitle#==#
Organization#==#Harvard University
Abstract#==#Our work focuses on the biases that emerge in the natural language generation (NLG) task of sentence completion. In this paper, we introduce a mathematical framework of fairness for NLG followed by an evaluation of gender biases in two state-of-the-art language models. Our analysis provides a theoretical formulation for biases in NLG and empirical evidence that existing language generation models embed gender bias.
Author{1}{Firstname}#=%=#Catherine
Author{1}{Lastname}#=%=#Yeo
Author{1}{Username}#=%=#cyeo
Author{1}{Email}#=%=#cyeo@college.harvard.edu
Author{1}{Affiliation}#=%=#Harvard University
Author{2}{Firstname}#=%=#Alyssa
Author{2}{Lastname}#=%=#Chen
Author{2}{Username}#=%=#achen2022
Author{2}{Email}#=%=#alyssachen@college.harvard.edu
Author{2}{Affiliation}#=%=#Harvard University

==========