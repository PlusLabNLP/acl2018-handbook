SubmissionNumber#=%=#206
FinalPaperTitle#=%=#Measuring Sentiment Annotation Complexity of Text
ShortPaperTitle#=%=#Measuring Sentiment Annotation Complexity of Text
NumberOfPages#=%=#6
CopyrightSigned#=%=#Aditya Joshi
JobTitle#==#
Organization#==#IITB-Monash Research Academy, IIT Bombay, Mumbai, PIN: 400076, India.
Abstract#==#The effort required for a human annotator to detect sentiment is not uniform
for
all texts, irrespective of his/her expertise. We aim to predict a score that
quantifies this effort, using linguistic properties of the text. Our proposed
metric is called Sentiment Annotation Complexity (SAC). As for training data,
since any direct judgment of complexity by a human annotator is fraught with
subjectivity, we rely on cognitive evidence from eye-tracking. The sentences in
our dataset are labeled with SAC scores derived from eye-fixation duration.
Using linguistic features and annotated SACs, we train a regressor that
predicts the SAC with a best mean error rate of 22.02% for five-fold
cross-validation. We also study the correlation between a human annotator’s
perception of complexity and a machine’s confidence in polarity
determination. The merit of our work lies in (a) deciding the sentiment
annotation cost in, for example, a crowdsourcing setting,(b) choosing the right
classifier for sentiment prediction.
Author{1}{Firstname}#=%=#Aditya
Author{1}{Lastname}#=%=#Joshi
Author{1}{Email}#=%=#adityaj@cse.iitb.ac.in
Author{1}{Affiliation}#=%=#IITB-Monash Research Academy
Author{2}{Firstname}#=%=#Abhijit
Author{2}{Lastname}#=%=#Mishra
Author{2}{Email}#=%=#abhijitmishra.530@gmail.com
Author{2}{Affiliation}#=%=#Indian Institute of Technology Bombay
Author{3}{Firstname}#=%=#Nivvedan
Author{3}{Lastname}#=%=#Senthamilselvan
Author{3}{Email}#=%=#nivvedan@cse.iitb.ac.in
Author{3}{Affiliation}#=%=#IIT Bombay
Author{4}{Firstname}#=%=#Pushpak
Author{4}{Lastname}#=%=#Bhattacharyya
Author{4}{Email}#=%=#pushpakbh@gmail.com
Author{4}{Affiliation}#=%=#CSE Department, IIT Bombay

==========