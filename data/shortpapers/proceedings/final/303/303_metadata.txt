SubmissionNumber#=%=#303
FinalPaperTitle#=%=#Distributed Representations of Geographically Situated Language
ShortPaperTitle#=%=#Distributed Representations of Geographically Situated Language
NumberOfPages#=%=#7
CopyrightSigned#=%=#David Bamman
JobTitle#==#
Organization#==#CMU
Abstract#==#We introduce a model for incorporating contextual information (such as
geography) in learning vector-space representations of situated language. In
contrast to approaches to multimodal representation learning that have used
properties of the object being described (such as its color), our model
includes information about the subject (i.e., the speaker), allowing us to
learn the contours of a word's meaning that are shaped by the context in which
it is uttered. In a quantitative evaluation on the task of judging
geographically informed semantic similarity between representations learned
from 1.1 billion words of geo-located tweets, our joint model outperforms
comparable independent models that learn meaning in isolation.
Author{1}{Firstname}#=%=#David
Author{1}{Lastname}#=%=#Bamman
Author{1}{Email}#=%=#dbamman@cs.cmu.edu
Author{1}{Affiliation}#=%=#Carnegie Mellon University
Author{2}{Firstname}#=%=#Chris
Author{2}{Lastname}#=%=#Dyer
Author{2}{Email}#=%=#cdyer@cs.cmu.edu
Author{2}{Affiliation}#=%=#Carnegie Mellon University
Author{3}{Firstname}#=%=#Noah A.
Author{3}{Lastname}#=%=#Smith
Author{3}{Email}#=%=#nasmith@cs.cmu.edu
Author{3}{Affiliation}#=%=#Carnegie Mellon University

==========