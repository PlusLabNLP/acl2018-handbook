SubmissionNumber#=%=#515
FinalPaperTitle#=%=#Faster Phrase-Based Decoding by Refining Feature State
ShortPaperTitle#=%=#Faster Phrase-Based Decoding by Refining Feature State
NumberOfPages#=%=#6
CopyrightSigned#=%=#Kenneth Heafield
JobTitle#==#
Organization#==#Stanford University
353 Serra Mall Gates 235
Stanford, CA 94305
Abstract#==#We contribute a faster decoding algorithm for phrase-based machine translation.
 Translation hypotheses keep track of state, such as context for the language
model and coverage of words in the source sentence.  Most features depend upon
only part of the state, but traditional algorithms, including cube pruning,
handle state atomically.  For example, cube pruning will repeatedly query the
language model with hypotheses that differ only in source coverage, despite the
fact that source coverage is irrelevant to the language model.                       
  Our
key
contribution avoids this behavior by placing hypotheses into equivalence
classes, masking the parts of state that matter least to the score.  Moreover,
we exploit shared words in hypotheses to iteratively refine language model
scores rather than handling language model state atomically.  Since our
algorithm and cube pruning are both approximate, improvement can be used to
increase speed or accuracy.  When tuned to attain the same accuracy, our
algorithm is 4.0-7.7 times as fast as the Moses decoder with cube pruning.
Author{1}{Firstname}#=%=#Kenneth
Author{1}{Lastname}#=%=#Heafield
Author{1}{Email}#=%=#softconf@kheafield.com
Author{1}{Affiliation}#=%=#Stanford
Author{2}{Firstname}#=%=#Michael
Author{2}{Lastname}#=%=#Kayser
Author{2}{Email}#=%=#mkayser@stanford.edu
Author{2}{Affiliation}#=%=#Stanford
Author{3}{Firstname}#=%=#Christopher
Author{3}{Lastname}#=%=#Manning
Author{3}{Email}#=%=#manning@cs.stanford.edu
Author{3}{Affiliation}#=%=#Stanford University

==========