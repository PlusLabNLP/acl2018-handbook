SubmissionNumber#=%=#401
FinalPaperTitle#=%=#Dependency-Based Word Embeddings
ShortPaperTitle#=%=#Dependency-Based Word Embeddings
NumberOfPages#=%=#7
CopyrightSigned#=%=#Omer Levy
JobTitle#==#
Organization#==#Bar-Ilan University
Ramat-Gan, Israel
Abstract#==#While continuous word embeddings are gaining popularity, current models are
based solely on linear contexts. In this work, we generalize the skip-gram
model with negative sampling introduced by Mikolov \etal~ to include arbitrary
contexts. In particular, we perform experiments with dependency-based contexts,
and show that they produce markedly different embeddings. The dependency-based
embeddings are less topical and exhibit more functional similarity than the
original skip-gram embeddings.
Author{1}{Firstname}#=%=#Omer
Author{1}{Lastname}#=%=#Levy
Author{1}{Email}#=%=#omerlevy@cs.biu.ac.il
Author{1}{Affiliation}#=%=#Bar-Ilan University
Author{2}{Firstname}#=%=#Yoav
Author{2}{Lastname}#=%=#Goldberg
Author{2}{Email}#=%=#yoav.goldberg@gmail.com
Author{2}{Affiliation}#=%=#Bar Ilan University

==========