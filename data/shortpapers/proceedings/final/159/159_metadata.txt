SubmissionNumber#=%=#159
FinalPaperTitle#=%=#Learning Polylingual Topic Models from Code-Switched Social Media Documents
ShortPaperTitle#=%=#Learning Polylingual Topic Models from Code-Switched Social Media Documents
NumberOfPages#=%=#6
CopyrightSigned#=%=#Nanyun Peng
JobTitle#==#
Organization#==#Johns Hopkins University
Baltimore, MD 21218
Abstract#==#Code-switched documents are common in social media, providing evidence for
polylingual topic models to infer aligned topics across languages. We present
Code-Switched LDA (csLDA), which infers language specific topic distributions
based on code-switched docu- ments to facilitate multi-lingual corpus anal-
ysis. We experiment on two code-switching corpora (English-Spanish Twitter data
and English-Chinese Weibo data) and show that csLDA improves perplexity over
LDA, and learns semantically coherent aligned topics as judged by human
annotators.
Author{1}{Firstname}#=%=#Nanyun
Author{1}{Lastname}#=%=#Peng
Author{1}{Email}#=%=#pengnanyun@gmail.com
Author{1}{Affiliation}#=%=#Johns Hopkins University
Author{2}{Firstname}#=%=#Yiming
Author{2}{Lastname}#=%=#Wang
Author{2}{Email}#=%=#freewym@gmail.com
Author{2}{Affiliation}#=%=#Johns Hopkins University
Author{3}{Firstname}#=%=#Mark
Author{3}{Lastname}#=%=#Dredze
Author{3}{Email}#=%=#mdredze@cs.jhu.edu
Author{3}{Affiliation}#=%=#Johns Hopkins University

==========