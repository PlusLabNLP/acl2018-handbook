SubmissionNumber#=%=#415
FinalPaperTitle#=%=#EM Decipherment for Large Vocabularies
ShortPaperTitle#=%=#EM Decipherment for Large Vocabularies
NumberOfPages#=%=#6
CopyrightSigned#=%=#Malte Nuhn
JobTitle#==#
Organization#==#Human Language Technology and Pattern Recognition
Computer Science Department, RWTH Aachen University, Aachen, Germany
Abstract#==#This paper addresses the problem of EM based decipherment for large
vocabularies. Here, decipherment is essentially a tagging problem: Every cipher
token is tagged with some plaintext type. As with other tagging problems, this
one can be treated as a Hidden Markov Model (HMM), only here, the vocabularies
are large, so the usual O(NV^2) exact EM approach is infeasible. When faced
with this situation, many people turn to sampling. However, we propose to use a
type of approximate EM and show that it works well. The basic idea is to
collect fractional counts only over a small subset of links in the
forward-backward lattice. The subset is different for each iteration of EM. One
option is to use beam search to do the
subsetting. The second method restricts the successor words that are looked at,
for each hypothesis. It does this by consulting pre-computed tables of likely
n-grams and likely substitutions.
Author{1}{Firstname}#=%=#Malte
Author{1}{Lastname}#=%=#Nuhn
Author{1}{Email}#=%=#nuhn@cs.rwth-aachen.de
Author{1}{Affiliation}#=%=#RWTH Aachen University, i6
Author{2}{Firstname}#=%=#Hermann
Author{2}{Lastname}#=%=#Ney
Author{2}{Email}#=%=#ney@cs.rwth-aachen.de
Author{2}{Affiliation}#=%=#RWTH Aachen University

==========