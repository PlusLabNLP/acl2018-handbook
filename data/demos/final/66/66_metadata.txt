SubmissionNumber#=%=#66
FinalPaperTitle#=%=#CLIReval: Evaluating Machine Translation as a Cross-Lingual Information Retrieval Task
ShortPaperTitle#=%=#
NumberOfPages#=%=#8
CopyrightSigned#=%=#Shuo Sun
JobTitle#==#
Organization#==#Johns Hopkins University
Abstract#==#We present CLIReval, an easy-to-use toolkit for evaluating machine translation (MT) with the proxy task of cross-lingual information retrieval (CLIR). Contrary to what the project name might suggest, CLIReval does not actually require any annotated CLIR dataset. Instead, it automatically transforms translations and references used in MT evaluations into a synthetic CLIR dataset; it then sets up a standard search engine (Elasticsearch) and computes various information retrieval metrics (e.g., mean average precision) by treating the translations as documents to be retrieved. The idea is to gauge the quality of MT by its impact on the document translation approach to CLIR. As a case study, we run CLIReval on the "metrics shared task" of WMT2019; while this extrinsic metric is not intended to replace popular intrinsic metrics such as BLEU, results suggest CLIReval is competitive in many language pairs in terms of correlation to human judgments of quality. CLIReval is publicly available at https://github.com/ssun32/CLIReval.
Author{1}{Firstname}#=%=#Shuo
Author{1}{Lastname}#=%=#Sun
Author{1}{Username}#=%=#ssfei81
Author{1}{Email}#=%=#ssun32@jhu.edu
Author{1}{Affiliation}#=%=#Johns Hopkins University
Author{2}{Firstname}#=%=#Suzanna
Author{2}{Lastname}#=%=#Sia
Author{2}{Username}#=%=#suzyahyah_jhu
Author{2}{Email}#=%=#suzyahyah@gmail.com
Author{2}{Affiliation}#=%=#Johns Hopkins University
Author{3}{Firstname}#=%=#Kevin
Author{3}{Lastname}#=%=#Duh
Author{3}{Username}#=%=#kevinduh
Author{3}{Email}#=%=#kevinduh@cs.jhu.edu
Author{3}{Affiliation}#=%=#Johns Hopkins University

==========