SubmissionNumber#=%=#37
FinalPaperTitle#=%=#The AFRL IWSLT 2020 Systems: Work-From-Home Edition
ShortPaperTitle#=%=#
NumberOfPages#=%=#6
CopyrightSigned#=%=#NA
JobTitle#==#
Organization#==#Air Force Research Laboratory
Abstract#==#This report summarizes the Air Force Research Laboratory (AFRL) submission to the offline spoken language translation (SLT) task as part of the IWSLT 2020 evaluation campaign. As in previous years, we chose to adopt the cascade approach of using separate systems to perform speech activity detection, automatic speech recognition, sentence segmentation, and machine translation. All systems were neural based, including a fully-connected neural network for speech activity detection, a Kaldi factorized time delay neural network with recurrent neural network (RNN) language model rescoring for speech recognition, a bidirectional RNN with attention mechanism for sentence segmentation, and transformer networks trained with OpenNMT and Marian for machine translation. Our primary submission yielded BLEU scores of 21.28 on tst2019 and 23.33 on tst2020.
Author{1}{Firstname}#=%=#Brian
Author{1}{Lastname}#=%=#Ore
Author{1}{Email}#=%=#brian.ore.1@us.af.mil
Author{1}{Affiliation}#=%=#Air Force Research Laboratory
Author{2}{Firstname}#=%=#Eric
Author{2}{Lastname}#=%=#Hansen
Author{2}{Email}#=%=#eric.hansen.5@us.af.mil
Author{2}{Affiliation}#=%=#Air Force Research Laboratory
Author{3}{Firstname}#=%=#Tim
Author{3}{Lastname}#=%=#Anderson
Author{3}{Username}#=%=#timothy.anderson.20
Author{3}{Email}#=%=#timothy.anderson.20@us.af.mil
Author{3}{Affiliation}#=%=#Air Force Research Laboratory
Author{4}{Firstname}#=%=#Jeremy
Author{4}{Lastname}#=%=#Gwinnup
Author{4}{Username}#=%=#jgwinnup
Author{4}{Email}#=%=#jeremy.gwinnup.1@us.af.mil
Author{4}{Affiliation}#=%=#Air Force Research Laboratory

==========