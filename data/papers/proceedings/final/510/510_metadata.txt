SubmissionNumber#=%=#510
FinalPaperTitle#=%=#Perplexity on Reduced Corpora
ShortPaperTitle#=%=#Perplexity on Reduced Corpora
NumberOfPages#=%=#10
CopyrightSigned#=%=#Hayato Kobayashi
JobTitle#==#
Organization#==#Yahoo Japan Corporation
9-7-1 Akasaka, Minato-ku, Tokyo 107-6211, Japan
Abstract#==#This paper studies the idea of removing low-frequency words from a corpus,
which is a common way to reduce computational costs,
from a theoretical standpoint.
Based on the assumption that a corpus follows Zipf's law,
we derive trade-off formulae of the perplexity of k-gram models and topic
models
with respect to the size of the reduced vocabulary.
In addition, 
we show the approximate behavior of each formula under certain conditions.
We verify the correctness of our theory on synthetic corpora
and examine the gap between theory and practice on real corpora.
Author{1}{Firstname}#=%=#Hayato
Author{1}{Lastname}#=%=#Kobayashi
Author{1}{Email}#=%=#hayato.kobayashi@gmail.com
Author{1}{Affiliation}#=%=#Yahoo Japan Corporation

==========