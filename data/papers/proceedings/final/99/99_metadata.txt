SubmissionNumber#=%=#99
FinalPaperTitle#=%=#Don't count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors
ShortPaperTitle#=%=#Don't count, predict!
NumberOfPages#=%=#10
CopyrightSigned#=%=#Marco Baroni
JobTitle#==#
Organization#==#Center for Mind/Brain Sciences, University of Trento
C.so Bettini 31, 38068 Rovereto, Italy
Abstract#==#Context-predicting models (more commonly known as embeddings or neural language
models) are the new kids on the distributional semantics block. Despite the
buzz surrounding these models, the literature is still lacking a systematic
comparison of the predictive models with classic, count-vector-based
distributional semantic approaches. In this paper, we perform such an extensive
evaluation, on a wide range of lexical semantics tasks and across many
parameter settings. The results, to our own surprise, show that the buzz is
fully justified, as the context-predicting models obtain a thorough and
resounding victory against their count-based counterparts.
Author{1}{Firstname}#=%=#Marco
Author{1}{Lastname}#=%=#Baroni
Author{1}{Email}#=%=#marco.baroni@unitn.it
Author{1}{Affiliation}#=%=#University of Trento
Author{2}{Firstname}#=%=#Georgiana
Author{2}{Lastname}#=%=#Dinu
Author{2}{Email}#=%=#georgiana.dinu@unitn.it
Author{2}{Affiliation}#=%=#University of Trento
Author{3}{Firstname}#=%=#Germ√°n
Author{3}{Lastname}#=%=#Kruszewski
Author{3}{Email}#=%=#german.kruszewski@unitn.it
Author{3}{Affiliation}#=%=#University of Trento

==========