SubmissionNumber#=%=#179
FinalPaperTitle#=%=#Structured Learning for Taxonomy Induction with Belief Propagation
ShortPaperTitle#=%=#Structured Learning for Taxonomy Induction with Belief Propagation
NumberOfPages#=%=#11
CopyrightSigned#=%=#Mohit Bansal
JobTitle#==#Res. Assistant Professor
Organization#==#Toyota Technological Institute at Chicago
Abstract#==#We present a structured learning approach to inducing hypernym taxonomies using
a probabilistic graphical model formulation. Our model incorporates
heterogeneous relational evidence about both hypernymy and siblinghood,
captured by semantic features based on patterns and statistics from Web n-grams
and Wikipedia abstracts. For efficient inference over taxonomy structures, we
use loopy belief propagation along with a directed spanning tree algorithm for
the core hypernymy factor. To train the system, we extract sub-structures of
WordNet and discriminatively learn to reproduce them, using adaptive
subgradient stochastic optimization. On the task of reproducing sub-hierarchies
of WordNet, our approach achieves a 51% error reduction over a chance baseline,
including a 15% error reduction due to the non-hypernym-factored sibling
features. On a comparison setup, we find up to 29% relative error reduction
over previous work on ancestor F1.
Author{1}{Firstname}#=%=#Mohit
Author{1}{Lastname}#=%=#Bansal
Author{1}{Email}#=%=#mbansal@ttic.edu
Author{1}{Affiliation}#=%=#Toyota Technological Institute at Chicago
Author{2}{Firstname}#=%=#David
Author{2}{Lastname}#=%=#Burkett
Author{2}{Email}#=%=#dburkett@twitter.com
Author{2}{Affiliation}#=%=#Twitter Inc.
Author{3}{Firstname}#=%=#Gerard
Author{3}{Lastname}#=%=#de Melo
Author{3}{Email}#=%=#gdm@demelo.org
Author{3}{Affiliation}#=%=#Tsinghua University
Author{4}{Firstname}#=%=#Dan
Author{4}{Lastname}#=%=#Klein
Author{4}{Email}#=%=#klein@cs.berkeley.edu
Author{4}{Affiliation}#=%=#University of California Berkeley

==========