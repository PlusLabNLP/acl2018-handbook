SubmissionNumber#=%=#416
FinalPaperTitle#=%=#Single-Agent vs. Multi-Agent Techniques for Concurrent Reinforcement Learning of Negotiation Dialogue Policies
ShortPaperTitle#=%=#Single-Agent vs. Multi-Agent Techniques for Concurrent Reinforcement Learning of Negotiation Dialogue Policies
NumberOfPages#=%=#11
CopyrightSigned#=%=#Kallirroi Georgila
JobTitle#==#
Organization#==#University of Southern California Institute for Creative Technologies, 12015 Waterfront Drive, Playa Vista, CA 90094, USA
Abstract#==#We use single-agent and multi-agent Reinforcement Learning (RL) for learning
dialogue policies in a resource allocation negotiation scenario. Two agents
learn concurrently by interacting with each other without any need for
simulated users (SUs) to train against or corpora to learn from. In particular,
we compare the Q-learning, Policy Hill-Climbing (PHC) and Win or Learn Fast
Policy Hill-Climbing (PHC-WoLF) algorithms, varying the scenario complexity
(state space size), the number of training episodes, the learning rate, and the
exploration rate. Our results show that generally Q-learning fails to converge
whereas PHC and PHC-WoLF always converge and perform similarly. We also show
that very high gradually decreasing exploration rates are required for
convergence. We conclude that multi-agent RL of dialogue policies is a
promising alternative to using single-agent RL and SUs or learning directly
from corpora.
Author{1}{Firstname}#=%=#Kallirroi
Author{1}{Lastname}#=%=#Georgila
Author{1}{Email}#=%=#kgeorgila@ict.usc.edu
Author{1}{Affiliation}#=%=#University of Southern California Institute for Creative Technologies
Author{2}{Firstname}#=%=#Claire
Author{2}{Lastname}#=%=#Nelson
Author{2}{Email}#=%=#cnelson@ict.usc.edu
Author{2}{Affiliation}#=%=#University of Southern California Institute for Creative Technologies
Author{3}{Firstname}#=%=#David
Author{3}{Lastname}#=%=#Traum
Author{3}{Email}#=%=#traum@ict.usc.edu
Author{3}{Affiliation}#=%=#University of Southern California Institute for Creative Technologies

==========