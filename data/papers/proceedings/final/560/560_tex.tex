
\documentclass[11pt]{article}
\usepackage{acl2014}
\usepackage{times}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bussproofs}
\usepackage[pdftex]{graphicx}
\usepackage{url}
\def\den#1{[\![#1]\!]}

\setlength\titlebox{5cm}    % Expanding the titlebox

\title{Logical Inference on Dependency-based Compositional Semantics}

\author{Ran Tian\quad\quad Yusuke Miyao \quad\quad Takuya Matsuzaki\\
  National Institute of Informatics, Japan \\
  {\{tianran,yusuke,takuya-matsuzaki\}@nii.ac.jp} \\
}

\date{}

\begin{document}
\maketitle
\begin{abstract}

Dependency-based Compositional Semantics (DCS) is a framework of
natural language semantics with easy-to-process structures as well as
strict semantics.
In this paper, we equip the DCS framework with logical inference, by defining \textit{abstract 
denotations} as an abstraction of the computing process of denotations in original DCS. An inference 
engine is built to achieve inference on abstract denotations. Furthermore, we propose a way to 
generate on-the-fly knowledge in logical inference, by combining our framework with the 
idea of tree transformation. Experiments on FraCaS and PASCAL RTE datasets show 
promising results.
\end{abstract}

\section{Introduction}
\label{sec:introduction}

Dependency-based Compositional Semantics (DCS) provides an intuitive way to model semantics of 
questions, by using simple dependency-like trees \cite{liang11}. 
It is expressive enough to represent complex natural language queries on a relational 
database, yet 
simple enough to be latently learned from question-answer pairs. In this paper, we equip DCS with 
\emph{logical inference}, 
which, in one point of view, is ``the best way of testing an NLP system's semantic capacity" \cite{fracas}. 

It should be noted that, however, a framework primarily designed for question answering 
is not readily suited for logical inference. Because, answers returned by a query 
depend on the specific database, but implication is independent of any databases. 
For example, answers to the question ``\textit{What books are read by students?}", should always 
be a subset of answers to ``\textit{What books are ever read by anyone?}", no matter how we store 
the data of students and how many records of books are there in our database. 

Thus, our first step is to fix a notation which abstracts the calculation process of DCS trees, 
so as to clarify its meaning without the aid of any existing database. The idea is to 
borrow a minimal set of operators from relational algebra \cite{Codd70}, which is already able 
to formulate 
the calculation in DCS and define \textit{abstract denotation}, which is an abstraction of 
the \emph{computation} of denotations guided by DCS trees. Meanings of sentences then can be represented 
by primary relations among abstract denotations. This formulation keeps 
the simpleness and computability of DCS trees mostly unaffected; for example, our semantic calculation 
for DCS trees is parallel to the denotation computation in original DCS. 

An inference engine is built to handle inference on abstract denotations. Moreover, to compensate 
the lack of background knowledge in practical inference, we combine our 
framework with the idea of tree 
transformation \cite{barheim07}, to propose a way of generating knowledge in 
logical representation from entailment rules \cite{szpektor07}, which are by now typically 
considered as syntactic rewriting rules. 

We test our system on FraCaS \cite{fracas} and PASCAL RTE datasets \cite{pascalrte}. 
The experiments show: (i) a competitive performance on FraCaS dataset; (ii) a big impact of 
our automatically generated on-the-fly knowledge in achieving high recall for a logic-based RTE system; 
and (iii) a result that outperforms state-of-the-art RTE system on RTE5 data. Our 
whole system is publicly released and can be downloaded from 
\url{http://kmcs.nii.ac.jp/tianran/tifmo/}.

\section{The Idea}
\label{sec:idea}

In this section we describe the idea of representing natural
language semantics by DCS trees, and achieving inference by computing logical 
relations among the corresponding abstract denotations.

\subsection{DCS trees}
\label{sec:dcstrees}

\begin{figure}[t]
\centering
\includegraphics[scale=0.40,bb=10 20 200 80,clip]{read.pdf}
\caption{The DCS tree of ``\emph{students read books}''}
\label{fig:dcstree}
\end{figure}

\begin{table}[t]
\centering
\scriptsize
\begin{tabular}{|c|}
\multicolumn{1}{c}{\emph{student}} \\
\hline
\texttt{ARG} \\
\hline
Mark \\
John \\
Emily \\
... \\
\hline
\end{tabular}
\begin{tabular}{|c|}
\multicolumn{1}{c}{\emph{book}} \\
\hline
\texttt{ARG} \\
\hline
A Tale of Two Cities \\
Ulysses \\
... \\
\hline
\end{tabular}
\begin{tabular}{| c | c |}
\multicolumn{2}{c}{\emph{read}} \\
\hline
\texttt{SUBJ} & \texttt{OBJ} \\
\hline
 Mark & New York Times \\
 Mary & A Tale of Two Cities \\
 John & Ulysses \\
 ... & ... \\
\hline
\end{tabular}
\caption{Databases of \emph{student}, \emph{book}, and \emph{read}}
\label{tab:readdb}
\end{table}

DCS trees has been proposed to 
represent natural language semantics with a structure similar to
dependency trees \cite{liang11} (Figure~\ref{fig:dcstree}). 
For the sentence ``\emph{students read books}'', imagine a 
database consists of three tables, namely, a set of students, a set 
of books, and a set of ``reading'' events (Table~\ref{tab:readdb}).
The DCS tree in Figure~\ref{fig:dcstree} is interpreted as a command 
for querying these tables, obtaining ``reading'' entries whose 
``\texttt{SUBJ}'' field is \textbf{student} and whose ``\texttt{OBJ}''
field is \textbf{book}.  The result is 
a set $\{\textit{John reads Ulysses},\ldots\}$, which is called a 
\emph{denotation}. 

DCS trees can be extended to represent
linguistic phenomena such as quantification and coreference, with additional markers 
introducing additional operations on tables.
Figure~\ref{fig:book} shows an example with a quantifier ``\emph{every}'', 
which is marked as ``$\subset$'' on
the edge $(\textbf{love})\texttt{OBJ-ARG}(\textbf{dog})$ and interpreted 
as a \emph{division operator} $q_{\subset}^{\texttt{OBJ}}$ (\S\ref{sec:abstdenno}). 
Optimistically, we believe DCS can provide a framework of semantic representation with
sufficiently wide coverage for real-world texts.

\begin{figure}[t]
\centering
\includegraphics[scale=0.40,bb=0 0 400 160,clip]{book.pdf}
\caption{DCS trees of ``\textit{Mary loves every dog}'' (Left-Up), ``\textit{Tom has a dog}'' (Left-Down), 
and ``\textit{Tom has an animal that Mary loves}'' (Right).}
\label{fig:book}
\end{figure}

The strict semantics of DCS trees brings us the idea of applying DCS
to logical inference. This is not trivial, however, because
DCS works under the assumption that databases are explicitly available.  
Obviously this is unrealistic for logical inference on
unrestricted texts, because we cannot prepare a database for everything 
in the world.  This fact fairly restricts the applicable tasks of DCS.

Our solution is to redefine DCS trees without the aid of any databases, 
by considering each node of a DCS tree as a content word in a sentence 
(but may no longer be a table in a specific database), 
while each edge represents semantic relations between two words. 
The labels on both ends of an edge, such as \texttt{SUBJ} (subject) and 
\texttt{OBJ} (object), are considered as \emph{semantic roles} of the 
corresponding words\footnote{The semantic role 
\texttt{ARG} is specifically defined for denoting nominal 
predicate.}. To formulate the database querying process defined by a 
DCS tree, we provide formal semantics to DCS trees by employing
\emph{relational algebra} \cite{Codd70} for representing the query. 
As described below, we represent meanings of sentences with 
\emph{abstract denotations}, and logical relations among sentences are computed 
as relations among their abstract denotations. In this way, we can 
perform inference over formulas of
relational algebra, without computing database entries explicitly.

\subsection{Abstract denotations}
\label{sec:abstdenno}

\emph{Abstract denotations} are formulas constructed from a minimal set of relational 
algebra \cite{Codd70} operators, which is already able to formulate the database queries 
defined by DCS trees. 

For example, the semantics of ``\emph{students read books}'' is
given by the abstract denotation:
$$
F_1=\textbf{read}\cap
(\textbf{student}_{\texttt{SUBJ}}\times \textbf{book}_{\texttt{OBJ}}),
$$
where \textbf{read}, \textbf{student} and \textbf{book} denote sets
represented by these words respectively, and $w_r$ represents the set
$w$ considered as the domain of the semantic role $r$ (e.g. $\textbf{book}_{\texttt{OBJ}}$ is 
the set of books considered as objects).  The operators
$\cap$ and $\times$ represent intersection and Cartesian product
respectively, both borrowed from relational algebra. 
It is not hard to see the abstract denotation denotes the intersection of the 
``\emph{reading}'' set (as illustrated by the ``\emph{read}'' table in Table~\ref{tab:readdb}) 
with the product of ``\emph{student}'' set and ``\emph{book}'' set,  
which results in the same denotation as computed by the DCS tree in Figure~\ref{fig:dcstree}, 
i.e. $\{\textit{John reads Ulysses},\ldots\}$. However, the point is that 
$F_1$ itself is an algebraic formula that does not depend on any concrete databases.

Formally, we introduce the following \emph{constants}:
\begin{itemize}
\item $W$: a universal set containing all entities. 
\item Content words: a content word (e.g. \textit{read}) defines a set 
representing the word (e.g. $\textbf{read}\!=\!\{(x,y)\;|\;read(x,y)\}$). 
\end{itemize}

In addition we introduce following \emph{functions}:
\begin{itemize}
\item $\times$: the Cartesian product of two sets.
\item $\cap$: the intersection of two sets.
\item $\pi_r$: projection onto domain of semantic role $r$ (e.g. 
$\pi_{\texttt{OBJ}}(\textbf{read})\!=\!\{y\;|\;\exists x;read(x,y)\}$). Generally 
we admit projections onto multiple semantics roles, denoted by $\pi_R$ where $R$ is 
a set of semantic roles. 
\item $\iota_r$: relabeling (e.g. $\iota_{\texttt{OBJ}}(\textbf{book})=\textbf{book}_{\texttt{OBJ}}$). 
\item $q_{\subset}^{r}$: the division operator, where $q_{\subset}^{r}(A,B)$ is defined as the 
largest set $X$ which satisfies $B_r\times X\subset A$.\footnote{If $A$ and $B$ has 
the same dimension, $q_{\subset}(A,B)$ is either $\emptyset$ or $\{*\}$ ($0$-dimension point set), 
depending on if $A\subset B$.} 
This is used to formulate universal quantifiers, such as 
``\textit{Mary loves every dog}'' and ``\textit{books read by all students}''. 
\end{itemize}
An \emph{abstract denotation} is then defined as finite applications of functions on either constants 
or other abstract denotations. 

\subsection{Statements}
As the semantics of DCS trees is formulated by abstract denotations, 
the meanings of declarative sentences are represented by \emph{statements} 
on abstract denotations. Statements are declarations of some relations 
among abstract denotations, for which we consider the following set relations:

\vspace{4pt}
\noindent\textit{Non-emptiness} $A\ne\emptyset$: the set $A$ is not empty. 

\noindent\textit{Subsumption} $A\subset B$: set $A$ is subsumed by $B$.\footnote{Using 
division operator, subsumption can be represented by non-emptiness, since for sets $A$, $B$ 
of the same dimension, $q_{\subset}(A,B)\ne\emptyset\Leftrightarrow A\subset B$.} 
\vspace{4pt}

\noindent Roughly speaking, the relations correspond to
the logical concepts \emph{satisfiability} and \emph{entailment}.

\begin{table}
\centering
\scriptsize
\begin{tabular}{@{}l@{\hspace{.5em}}l@{\hspace{.5em}}l@{}}
\hline
& example phrase & abstract denotation / statement \\
\hline
compound noun &
\emph{pet fish} &
$\textbf{pet}\cap\textbf{fish}$ \\
modification &
\emph{nice day} &
$\textbf{day}\cap(W_{\texttt{ARG}}\times\textbf{nice}_{\texttt{MOD}})$ \\
temporal relation &
\emph{boys study at night} &
$\textbf{study}\cap(\textbf{boy}_{\texttt{SUBJ}}\times\textbf{night}_{\texttt{TIME}})$ \\
relative clause &
\emph{books that} &
$\textbf{book}\cap\pi_{\texttt{OBJ}}(\textbf{read}$ \\
& \hspace{1.7em}\emph{students read} & \hspace{2em}$\cap(\textbf{student}_{\texttt{SUBJ}}\times
W_{\texttt{OBJ}}))$ \\
quantification &
\emph{all men die} &
$\textbf{man}\subset\pi_{\texttt{SUBJ}}(\textbf{die})$ \\
hypernym & 
 & 
$\textbf{dog}\subset\textbf{animal}$ \\
derivation & 
\emph{all criminals commit} & $\textbf{criminal}\subset\pi_{\texttt{SUBJ}}(\textbf{commit}\cap$ \\
 & \hspace{5.5em}\emph{a crime} & \hspace{3.9em}$(W_{\texttt{SUBJ}}\times\textbf{crime}_{\texttt{OBJ}}))$ \\
antonym & 
 & 
$\textbf{rise}\parallel\textbf{fall}$ \\
negation & 
\emph{no dogs are hurt} &
$\textbf{dog}\parallel\pi_{\texttt{OBJ}}(\textbf{hurt})$ \\
\hline
\end{tabular}
\caption{Abstract denotations and statements}
\label{tab:algebraic_forms}
\end{table}

Abstract denotations and statements are convenient for 
representing semantics of various types of expressions and linguistic 
knowledge. Some examples are shown in 
Table~\ref{tab:algebraic_forms}.\footnote{Negation and disjointness (``$\parallel$'') are 
explained in \S\ref{sec:extensions}.} 


\subsection{Logical inference on DCS}
\label{sec:formalization}

Based on abstract denotations, we briefly describe our process to apply DCS to 
textual inference. 

\subsubsection{Natural language to DCS trees}

To obtain DCS trees from natural language, we use Stanford 
CoreNLP\footnote{\url{http://nlp.stanford.edu/software/corenlp.shtml}} 
for dependency parsing \cite{socher13}, and convert Stanford dependencies to DCS trees by pattern matching on POS tags and dependency 
labels.\footnote{In 
\cite{liang11} DCS trees are learned from QA 
pairs and database entries. We obtain DCS trees from dependency trees, to bypass the 
need of a concrete database.} 
Currently we use the following
semantic roles: \texttt{ARG}, \texttt{SUBJ}, \texttt{OBJ}, 
\texttt{IOBJ}, \texttt{TIME} and \texttt{MOD}. The semantic role \texttt{MOD} is used for any 
restrictive modifiers. Determiners such as ``all", ``every" and ``each" 
trigger quantifiers, as shown in Figure~\ref{fig:book}. 

\begin{figure*}[t]
\centering
\scriptsize
\begin{prooftree}
\def\defaultHypSeparation{\hskip 3pt}
	\AxiomC{$\pi_{\texttt{OBJ}}(F_4)=F_3\cap F_7$}
			\AxiomC{$\pi_{\texttt{OBJ}}(F_6)=\textbf{dog}\cap F_7$}
				\AxiomC{\textbf{T}}
			\UnaryInfC{$F_6\neq\emptyset$}
			\AxiomC{Axiom 4}
		\TrinaryInfC{$\textbf{dog}\cap F_7\neq\emptyset$}
					\AxiomC{\textbf{T}}
				\UnaryInfC{$\textbf{dog}\subset\pi_{\texttt{OBJ}}(F_2)$}
				\AxiomC{$\textbf{dog}\subset\textbf{animal}$}
				\AxiomC{Axiom 8}
			\TrinaryInfC{$\textbf{dog}\subset F_3$}
		\UnaryInfC{$\textbf{dog}\cap F_7\subset F_3\cap F_7$}
		\AxiomC{Axiom 6}
	\TrinaryInfC{$F_3\cap F_7\neq\emptyset$}
	\AxiomC{Axiom 4}
\TrinaryInfC{$F_4\neq\emptyset$}
\end{prooftree}
\caption{An example of proof using abstract denotations}
\label{tab:proof}
\end{figure*}

\subsubsection{DCS trees to statements}

A DCS tree $\mathcal{T}=(\mathcal{N},\mathcal{E})$ is defined as a rooted tree,
where each node $\sigma\in\mathcal{N}$ is labeled with a content word 
$w(\sigma)$ and each edge $(\sigma,\sigma')\in\mathcal{E}\subset\mathcal{N}\times\mathcal{N}$ 
is labeled with a pair of semantic roles $(r,r')$\footnote{The 
definition differs slightly from the original \newcite{liang11}, 
mainly for the sake of simplicity and clarity.}. 
Here $\sigma$ is the node nearer to the root. Furthermore, for each edge $(\sigma,\sigma')$ we 
can optionally assign a quantification marker. 

Abstract denotation of a DCS tree can be calculated in a bottom-up manner. 
For example, the abstract denotation of {\bf H} in Figure~\ref{fig:book} is 
calculated from the leaf node $\textbf{Mary}$, and then: 

\vspace{4pt}
\noindent Node $\textbf{love}$ (\emph{Mary loves}): \\
\indent\quad$F_2=\textbf{love}\cap(\textbf{Mary}_{\texttt{SUBJ}}\times W_{\texttt{OBJ}})$

\noindent Node $\textbf{animal}$ (\emph{Animal that Mary loves}): \\
\indent\quad$F_3=\textbf{animal}\cap\pi_{\texttt{OBJ}}(F_2)$

\noindent Node $\textbf{have}$ (\emph{Tom has an animal that Mary loves}): \\
\indent\quad$F_4=\textbf{have}\cap(\textbf{Tom}_{\texttt{SUBJ}}\times (F_{3})_{\texttt{OBJ}})$. 
\vspace{4pt}

\noindent Formally, suppose the root $\sigma$ of a DCS tree $\mathcal{T}$ has children
$\tau_1,\ldots,\tau_n$, and edges $(\sigma, \tau_1),\ldots,(\sigma, \tau_n)$
labeled by $(r_1, r'_1),\ldots,(r_n, r'_n)$, respectively. 
The abstract denotation of $\mathcal{T}$ is defined as:
$$
\den{\mathcal{T}}\!=\!
w(\sigma)\cap
(\bigcap_{i=1}^n \iota_{r_i}(\pi_{r'_i}(\den{\mathcal{T}_{\tau_i}}))
\times W_{R_{\sigma}\setminus r_i}),
$$
where $\mathcal{T}_{\tau_i}$ is the subtree of $\mathcal{T}$ rooted at
$\tau_i$, and $R_{\sigma}$ is the set of possible semantic roles for content word 
$w(\sigma)$ (e.g. $R_{\textbf{love}}=\{\texttt{SUBJ},\texttt{OBJ}\}$), 
and $W_{R_{\sigma}\setminus r_i}$ is the product of $W$ 
which has dimension $R_{\sigma}\setminus r_i$ (e.g. 
$W_{\{\texttt{SUBJ},\texttt{OBJ}\}\setminus\texttt{SUBJ}}=W_{\texttt{OBJ}}$). 

When universal quantifiers are involved, we need to add division operators 
to the formula. If $(\sigma,\tau_i)$ is assigned by a 
quantification marker ``$\subset$''\footnote{Multiple quantifiers
can be processed similarly.}, then the abstract denotation 
is\footnote{The result of $\den{\mathcal{T}}$ 
depends on the order of the children $\tau_1,\ldots,\tau_n$. Different orders 
correspond to readings of different quantifier scopes.} 
$$
\den{\mathcal{T}}\!=\!
q_{\subset}^{r_i}(\pi_{R_{\sigma}\setminus\{r_1,\ldots,r_{i-1}\}}(\den{\mathcal{T}'}),
\pi_{r_i'}(\den{\mathcal{T}_{\tau_i}})),
$$
where $\mathcal{T}'$ is the same tree as $\mathcal{T}$ except that 
the edge $(\sigma,\tau_i)$ is removed. For example, the abstract 
denotation of the first sentence of {\bf T} in Figure~\ref{fig:book} 
(\textit{Mary loves every dog}) is calculated from $F_2$ (\emph{Mary loves}) as 
$$
F_5=q_{\subset}^{\texttt{OBJ}}(\pi_{\texttt{OBJ}}(F_2), \textbf{dog}). 
$$

After the abstract denotation $\den{\mathcal{T}}$ is calculated, 
the statement representing the meaning of the sentence is defined as 
$\den{\mathcal{T}}\ne\emptyset$. For example, the statement of ``\textit{students read books}'' 
is $\textbf{read}\cap(\textbf{student}_{\texttt{SUBJ}}\times 
\textbf{book}_{\texttt{OBJ}})\ne\emptyset$, and 
the statement of ``\textit{Mary loves every dog}'' 
is $q_{\subset}^{\texttt{OBJ}}(\pi_{\texttt{OBJ}}(F_2), \textbf{dog})\ne\emptyset$, 
which is logically equivalent to $\textbf{dog}\subset\pi_{\texttt{OBJ}}(F_2)$.\footnote{See 
Footnote~2,3.}

\subsubsection{Logical inference}

\begin{table}[t]
\centering
\scriptsize
\begin{tabular}{@{}l@{}}
\hline
1. $W\neq\emptyset$ \\
2. $A\cap B\subset A$ \\
3. $B_r\times q^r_{\subset}(A, B)\subset A$ \\
4. $\pi_R(A)\neq\emptyset\Leftrightarrow A\neq\emptyset$ \\
\hline
\end{tabular}
\hspace{0.3em}
\begin{tabular}{@{}l@{}}
\hline
5. $(A\subset B \;\&\; B\subset C)\Rightarrow A\subset C$ \\
6. $(A\subset B \;\&\; A\neq\emptyset)\Rightarrow B\neq\emptyset$ \\
7. $A\subset B\Rightarrow \pi_R(A)\subset \pi_R(B)$ \\
8. $(C\subset A \;\&\; C\subset B)\Rightarrow C\subset A\cap B$ \\
\hline
\end{tabular}
\caption{An excerpt of axioms}
\label{tab:axioms}
\end{table}

Since meanings of sentences are represented by 
statements on abstract denotations, logical inference 
among sentences is reduced to deriving new relations among 
abstract denotations. This is done by applying axioms to known statements, and approximately 
30 axioms are implemented (Table~\ref{tab:axioms}). 
These are algebraic properties of abstract denotations, 
among which we choose a set of axioms that can be handled efficiently and enable 
most common types of inference seen in natural language. 

For the example in Figure~\ref{fig:book}, by constructing the following abstract denotations: 

\vspace{4pt}
\noindent \emph{Tom has a dog}: \\
\indent\quad $F_6=\textbf{have}\cap(\textbf{Tom}_{\texttt{SUBJ}}\times\textbf{dog}_{\texttt{OBJ}})$

\noindent Objects \emph{that Tom has}: \\
\indent\quad $F_7=\pi_{\texttt{OBJ}}(\textbf{have}\cap(\textbf{Tom}_{\texttt{SUBJ}}\times W_{\texttt{OBJ}}))$, 
\vspace{4pt}

\noindent we can use the lexical knowledge 
$\textbf{dog}\subset\textbf{animal}$, the statements of {\bf T} 
(i.e. $\textbf{dog}\subset\pi_{\texttt{OBJ}}(F_2)$ and $F_6\neq\emptyset$), and the axioms in 
Table~\ref{tab:axioms},\footnote{Algebraic identities, such as $\pi_{\texttt{OBJ}}(F_4)=F_3\cap F_7$ 
and $\pi_{\texttt{OBJ}}(F_6)=\textbf{dog}\cap F_7$, are also axioms.} 
to prove the statement of {\bf H} (i.e. $F_4\ne\emptyset$) (Figure~\ref{tab:proof}). 

We built an inference engine to perform logical inference on abstract denotations 
as above. In this logical system, we treat abstract denotations as \emph{terms} and 
statements as \emph{atomic sentences}, which are far more easier to handle than 
first order predicate logic (FOL) formulas. Furthermore, all implemented axioms are 
horn clauses, hence we can employ forward-chaining, which is very efficient. 

\subsection{Extensions}
\label{sec:extensions}

Further extensions of our framework are made to deal with additional linguistic 
phenomena, as briefly explained below.

\paragraph{Negation} 
To deal with negation in our forward-chaining inference engine, we introduce 
one more relation on abstract denotations, namely \emph{disjointness} 
$A\parallel B$, meaning that $A$ and $B$ are disjoint sets. Using disjointness 
we implemented two types of negations: (i) atomic negation, for each content word $w$ 
we allow negation $\bar{w}$ of that word,
characterized by the property $w\parallel\bar{w}$; and (ii)
root negation, for a DCS tree $\mathcal{T}$ and its denotation $\den{\mathcal{T}}$, 
the negation of $\mathcal{T}$ is represented by $\mathcal{T}\parallel\mathcal{T}$, 
meaning that $\mathcal{T}=\emptyset$ in its effect. 

\paragraph{Selection}
Selection operators in relational algebra select a subset from a set to satisfy some specific
properties. This can be employed to represent linguistic phenomena such as 
downward monotonicity and 
generalized quantifiers. In the current system, we implement (i) 
superlatives, 
e.g. $s_{highest}(\textbf{mountain}\cap(W_{\texttt{ARG}}\times \textbf{Asia}_{\texttt{MOD}}))$ 
(the highest mountain in Asia) and (ii) numerics, e.g. $s_{two}(\textbf{pet}\cap\textbf{fish})$ 
(two pet fish), where $s_f$ is a selection marker.
Selection operators are implemented as markers assigned to abstract denotations, 
with specially designed axioms. For example 
superlatives satisfy the following property: 
$A\subset B \;\&\; s_{highest}(B)\subset A \Rightarrow s_{highest}(B)=s_{highest}(A)$. 
New rules can be added if necessary. 

\paragraph{Coreference}
We use Stanford CoreNLP to resolve coreferences \cite{raghunathan10}, 
whereas coreference is implemented as a special type of selection. 
If a node $\sigma$ in a DCS tree $\mathcal{T}$ belongs to a mention cluster $m$, 
we take the abstract denotation $\den{\mathcal{T}_{\sigma}}$ and make a selection 
$s_{m}(\den{\mathcal{T}_{\sigma}})$, which is regarded as the abstract denotation 
of that mention. Then all selections of the same mention cluster are declared to be equal. 

\section{Generating On-the-fly Knowledge}
\label{sec:sysoverview}

Recognizing textual entailment (RTE) is the task of determining whether a given textual 
statement {\bf H} can be inferred by a text passage {\bf T}. For this, 
our primary textual inference system operates as: 

\begin{enumerate}
\item For a {\bf T}-{\bf H} pair, apply dependency parsing and coreference resolution.
\item Perform rule-based conversion from dependency parses to DCS trees, which are 
translated to statements on abstract denotations.
\item Use statements of {\bf T} and linguistic knowledge as premises, and try to prove 
statements of {\bf H} by our inference engine.
\end{enumerate}

However, this method does not work for real-world datasets 
such as PASCAL RTE \cite{pascalrte}, because of the knowledge bottleneck: it is often
the case that the lack of sufficient linguistic knowledge causes
failure of inference, thus the system outputs ``no entailment''
for almost all pairs \cite{bos05}.

\begin{figure}[t]
\centering
\includegraphics[scale=0.25,bb=0 0 690 280,clip]{rte.pdf}
\caption{RTE system}
\label{fig:rte_system}
\end{figure}

The transparent syntax-to-semantics interface of DCS enables us to
back off to NLP techniques during inference for catching
up the lack of knowledge.  We extract fragments of DCS
trees as paraphrase candidates, translate them back
to linguistic expressions, and apply distributional similarity to judge their 
validity.  In this way, our
framework combines distributional and logical semantics, which is 
also the main subject of \newcite{lewis13} and \newcite{beltagy13}. 

As follows, our full system (Figure~\ref{fig:rte_system}) additionally invokes 
linguistic knowledge on-the-fly:
\begin{enumerate}
\setcounter{enumi}{3}
\item If {\bf H} is not proven, compare DCS trees of {\bf T} and
  {\bf H}, and generate path alignments.
\item Aligned paths are evaluated by a similarity score to estimate
  their likelihood of being paraphrases. Path alignments with scores 
  higher than a threshold are accepted.
\item Convert accepted path alignments into statements on
  abstract denotations, use them in logical inference as new
  knowledge, and try to prove {\bf H} again.
\end{enumerate}

\subsection{Generating path alignments}
\label{sec:ontheflygen}

On-the-fly knowledge is generated by aligning paths in DCS trees. 
A path is considered as joining two \emph{germs} in a DCS tree, where a \emph{germ} is defined 
as a specific semantic role of a node. For example, Figure~\ref{fig:debbydcs} shows DCS 
trees of the following sentences (a simplified pair from RTE2-dev):

\vspace{4pt}
\noindent{\bf T:} \textit{Tropical storm Debby is blamed for deaths.}\\
{\bf H:} \textit{A storm has caused loss of life.}
\vspace{4pt}

\noindent The germ $\texttt{OBJ}(\textbf{blame})$ and 
germ $\texttt{ARG}(\textbf{death})$ in DCS tree of {\bf T} are joined by the 
underscored path. Two paths are aligned if the joined germs are aligned, 
and we impose constraints on aligned germs to inhibit meaningless alignments, 
as described below. 

\subsection{Aligning germs by logical clues}

Two germs are aligned if they are both at leaf nodes (e.g. 
$\texttt{ARG}(\textbf{death})$ in {\bf T} and $\texttt{ARG}(\textbf{life})$ in {\bf H}, 
Figure~\ref{fig:debbydcs}), 
or they already have part of their meanings in common, by some logical clues. 

To formulate this properly, we define the abstract denotation of a germ, which, 
intuitively, represents the meaning of the germ in the specific sentence. 
The abstract denotation of a germ is defined in a top-down manner: 
for the root node $\rho$ of a DCS tree $\mathcal{T}$, 
we define its denotation $\den{\rho}_{\mathcal{T}}$ as the denotation 
of the entire tree $\den{\mathcal{T}}$; for a non-root node $\tau$ and its 
parent node $\sigma$, let the edge $(\sigma,\tau)$ be labeled by semantic roles 
$(r,r')$, then define 
$$
\den{\tau}_{\mathcal{T}}=\den{\mathcal{T}_{\tau}}\cap(\iota_{r'}
(\pi_{r}(\den{\sigma}_{\mathcal{T}}))\times W_{R_{\tau}\setminus r'}). 
$$
Now for a germ $r(\sigma)$, the denotation is defined as the projection of the denotation of 
node $\sigma$ onto the specific semantic role $r$: 
$\den{r(\sigma)}_{\mathcal{T}}=\pi_r(\den{\sigma}_{\mathcal{T}})$. 

For example, the abstract denotation of germ $\texttt{ARG}(\textbf{book})$ in 
Figure~\ref{fig:dcstree} is defined as $\pi_{\texttt{ARG}}(\textbf{book}\cap\pi_{\texttt{OBJ}}(\textbf{read}\cap(\textbf{student}_{\texttt{SUBJ}}\times\textbf{book}_{\texttt{OBJ}})))$, 
meaning ``\emph{books read by students}''. 
Similarly, denotation of germ $\texttt{OBJ}(\textbf{blame})$ in {\bf T} of 
Figure~\ref{fig:debbydcs} indicates the object of ``\textit{blame}'' as in the sentence 
``\textit{Tropical storm Debby is blamed for death}'', which is a \textit{tropical storm}, 
is \textit{Debby}, etc. 
Technically, each germ in a DCS tree indicates a variable when the DCS tree is translated to 
a FOL formula, and the abstract denotation of the germ corresponds to the set of 
\emph{consistent values} \cite{liang11} of that variable. 

\begin{figure}[t]
\centering
\includegraphics[scale=0.45,bb=0 0 500 150,clip]{debbydcs.pdf}
\caption{Aligned paths (underscored by the solid lines) and aligned germs
  (joined by the dotted line)}
\label{fig:debbydcs}
\end{figure}

The logical clue to align germs is: if there exists an abstract denotation, other than 
$W$, that is a superset of both abstract denotations of two germs, then the two germs 
can be aligned. A simple example is that 
$\texttt{ARG}(\textbf{storm})$ in \textbf{T} can be aligned to 
$\texttt{ARG}(\textbf{storm})$ in \textbf{H}, because their denotations have a common 
superset other than $W$, namely $\pi_{\texttt{ARG}}(\textbf{storm})$.  
A more complicated example
is that $\texttt{OBJ}(\textbf{blame})$ and
$\texttt{SUBJ}(\textbf{cause})$ can be aligned, because inference can 
induce  
$\den{\mbox{\texttt{OBJ}}(\mbox{\textbf{blame}})}_{\mbox{\textbf{T}}}$ = 
$\den{\mbox{\texttt{ARG}}(\mbox{\textbf{Debby}})}_{\mbox{\textbf{T}}}$ = 
$\den{\mbox{\texttt{ARG}}(\mbox{\textbf{storm}})}_{\mbox{\textbf{T}}}$,
as well as
$\den{\mbox{\texttt{SUBJ}}(\mbox{\textbf{cause}})}_{\mbox{\textbf{H}}}$ = 
$\den{\mbox{\texttt{ARG}}(\mbox{\textbf{storm}})}_{\mbox{\textbf{H}}}$, 
so they also have the common superset $\pi_{\texttt{ARG}}(\textbf{storm})$. 
However, for example, logical clues can avoid aligning 
$\texttt{ARG}(\textbf{storm})$ to $\texttt{ARG}(\textbf{loss})$, which 
is obviously meaningless.

\subsection{Scoring path alignments by similarity}

Aligned paths are evaluated by a similarity score, for which we use 
distributional similarity of the words that appear in the paths (\S\ref{sec:implementation}). 
Only path alignments with high similarity scores can be accepted. 
Also, we only accept paths of length $\leq 5$, to prevent too long paths to be aligned. 

\subsection{Applying path alignments}
\label{sec:ontheflyapp}

\begin{figure}[t]
\centering
\includegraphics[scale=0.45,bb=0 10 500 180,clip]{debbytrans.pdf}
\caption{Tree transformation and generated on-the-fly knowledge 
(subsumption of denotations shown above the trees)}
\label{fig:debbytrans}
\end{figure}

Accepted aligned paths are converted into statements, which are used as 
new knowledge. The conversion is done by first performing a DCS tree transformation 
according to the aligned paths, and then declare a subsumption relation between the 
denotations of aligned germs. 
For example, to apply the aligned path pair generated in Figure~\ref{fig:debbydcs}, we use it 
to transform {\bf T} into a new tree {\bf T'} (Figure~\ref{fig:debbytrans}), and then the aligned germs, \texttt{OBJ}(\textbf{blame}) in {\bf T} and \texttt{SUBJ}(\textbf{cause}) in {\bf T'}, will 
generate the on-the-fly knowledge:
$\den{\mbox{\texttt{OBJ}}(\mbox{\textbf{blame}})}_{\mbox{\textbf{T}}}$ $\subset$ 
$\den{\mbox{\texttt{SUBJ}}(\mbox{\textbf{cause}})}_{\mbox{\textbf{T'}}}$. 

Similar to the tree transformation based approach to RTE \cite{barheim07}, 
this process can also utilize lexical-syntactic entailment rules \cite{szpektor07}. 
Furthermore, since the on-the-fly knowledge is generated by transformed
pairs of DCS trees, all contexts are preserved: in Figure~\ref{fig:debbytrans}, 
though the tree transformation can be seen as generated from the entailment rule 
``\textit{X is blamed for death $\rightarrow$ X causes loss of life}'', the generated 
on-the-fly knowledge, as shown above the trees, only fires with the additional 
condition that $X$ is a \textit{tropical storm} and is \textit{Debby}. Hence, the 
process can also be used to generate 
knowledge from context sensitive rules \cite{melamud13}, which are known to have higher quality 
\cite{pantel07,clark09}. 

However, it should be noted that using on-the-fly knowledge in logical inference is not a 
trivial task. For example, the FOL formula of 
the rule ``\textit{X is blamed for death $\rightarrow$ X causes loss of life}'' is:
\begin{multline*}
\forall x; (\exists a; blame(x,a) \;\&\; death(a))\rightarrow \\
(\exists b,c; cause(x,b) \;\&\; loss(b,c) \;\&\; life(c)), 
\end{multline*}
which is not a horn clause. The FOL formula for the context-preserved rule in 
Figure~\ref{fig:debbytrans} 
is even more involved. Still, it can be efficiently treated by our inference engine because 
as a statement, the formula $\den{\mbox{\texttt{OBJ}}(\mbox{\textbf{blame}})}_{\mbox{\textbf{T}}}$ 
$\subset$ 
$\den{\mbox{\texttt{SUBJ}}(\mbox{\textbf{cause}})}_{\mbox{\textbf{T'}}}$ is an atomic sentence, 
more than a horn clause. 

\section{Experiments}
\label{sec:experiments}

In this section, we evaluate our system on FraCaS (\S\ref{sec:experimentfracas}) and 
PASCAL RTE datasets (\S\ref{sec:experimentrte}).

\subsection{Language Resources}
\label{sec:implementation}

The lexical knowledge we use are synonyms, hypernyms and 
antonyms extracted from WordNet\footnote{\url{http://wordnet.princeton.edu/}}. 
We also add axioms on named entities, 
stopwords, numerics and superlatives. For example, named entities 
are singletons, so we add axioms such as 
$\forall x; (x\subset\mbox{\textbf{Tom}} \;\&\; 
x\neq\emptyset)\rightarrow\mbox{\textbf{Tom}}\subset x$. 

To calculate the similarity scores of path alignments, we use the sum of 
word vectors of the words from each path, and calculate the cosine similarity. 
For example, the similarity score of the path alignment 
``\texttt{OBJ}(\textbf{blame})\texttt{IOBJ}-\texttt{ARG}(\textbf{death}) $\approx$ 
\texttt{SUBJ}(\textbf{cause})\texttt{OBJ}-\texttt{ARG}(\textbf{loss})\texttt{MOD}-\texttt{ARG}(\textbf{life})'' is calculated as the cosine similarity of vectors 
\textbf{blame}+\textbf{death} and \textbf{cause}+\textbf{loss}+\textbf{life}. 
Other structures in the paths, such as semantic roles, are ignored in the calculation. 
The word vectors we use are from
\newcite{mikolov13}\footnote{\url{http://code.google.com/p/word2vec/}} (\textit{Mikolov13}), 
and additional results are also shown using 
\newcite{turian10}\footnote{\url{http://metaoptimize.com/projects/wordreprs/}}
(\textit{Turian10}). 
The threshold for accepted path alignments is set to $0.4$, 
based on pre-experiments on RTE development sets.

\subsection{Experiments on FraCaS}
\label{sec:experimentfracas}

The FraCaS test suite contains 346 inference problems divided into 9 sections, each focused on a category of semantic phenomena. We use the data by \newcite{maccartney07}, and experiment on the first section, \textit{Quantifiers}, following \newcite{lewis13}. 
This section has 44 single premise and 30 multi premise problems. 
Most of the problems do not require lexical knowledge, so we use our primary textual 
inference system without on-the-fly knowledge nor WordNet, to test the performance 
of the DCS framework as formal semantics. To obtain the three-valued output (i.e. \emph{yes}, 
\emph{no}, and \emph{unknown}), we output ``\emph{yes}'' if {\bf H} is proven, or try to 
prove the negation of {\bf H} if {\bf H} is not proven. To negate {\bf H}, we use the root 
negation as described in \S\ref{sec:extensions}. If the negation of {\bf H} is proven, we 
output ``\emph{no}'', otherwise we output ``\emph{unknown}''. 

The result is shown in Table~\ref{tab:fracasres}. Since 
our system uses an off-the-shelf dependency parser, and semantic representations are obtained 
from simple rule-based conversion from dependency trees, there will be only one (right or wrong) interpretation in face of ambiguous sentences. 
Still, our system outperforms \newcite{lewis13}'s probabilistic CCG-parser. 
Compared to \newcite{maccartney07} and \newcite{maccartney08}, 
our system does not need a pre-trained alignment model, 
and it improves by making multi-sentence inferences. 
To sum up, the result shows that DCS is good at handling universal quantifiers and negations. 

\begin{table}[t]
\footnotesize
\centering
\setlength{\tabcolsep}{4pt}
\begin{tabular}{|l | c c |}
\hline
 & Single Prem. & Multi Prem. \\
\hline
Lewis13 & 70 & 50 \\
MacCartney07 & 84.1 & - \\
MacCartney08 & \textbf{97.7} & - \\
Our Sys. & 79.5 & \textbf{80.0} \\
\hline
\end{tabular}
\caption{Accuracy (\%) on FraCaS}
\label{tab:fracasres}
\end{table}

Most errors are due to wrongly generated DCS trees (e.g. wrongly assigned semantic roles) or 
unimplemented quantifier triggers (e.g. ``\textit{neither}'') or generalized quantifiers 
(e.g. ``\textit{at least a few}''). These could be addressed by future work. 

\begin{table*}[t]
\centering
\footnotesize
\begin{tabular}{| l | c c c | c c c | c c c | c c c |}
\hline
& \multicolumn{3}{|c|}{RTE2} & \multicolumn{3}{c|}{RTE3} & \multicolumn{3}{c|}{RTE4} & \multicolumn{3}{c|}{RTE5} \\
\cline{2-13}
& Prec. & Rec. & Acc. & Prec. & Rec. & Acc. & Prec. & Rec. & Acc. & Prec. & Rec. & Acc.\\
\hline
Primary & \textbf{70.9} & 9.8 & 52.9 & \textbf{73.2} & 7.3 & 51.1 & \textbf{89.7} & 5.2 & 52.3 & \textbf{82.6} & 6.3 & 52.5 \\
+On-the-fly & 57.6 & \textbf{66.5} & \textbf{58.8} & 63.7 & \textbf{64.6} & \textbf{63.0} & 60.0 & \textbf{57.4} & \textbf{59.6} & 69.9 & \textbf{55.7} & \textbf{65.8} \\
\hline
\end{tabular}
\caption{Impact of on-the-fly knowledge}
\label{tab:precrec}
\end{table*}

\subsection{Experiments on PASCAL RTE datasets}
\label{sec:experimentrte}

On PASCAL RTE datasets, strict logical inference is known to have very low recall \cite{bos05}, 
so on-the-fly knowledge is crucial in this setting. We test the effect of on-the-fly knowledge
on RTE2, RTE3, RTE4 and RTE5 datasets, and compare our system with other approaches. 

\subsubsection{Impact of on-the-fly knowledge}

Results on test data are shown in Table~\ref{tab:precrec}. When only 
primary knowledge is used in inference (the first row), recalls are actually very low; After 
we activate the on-the-fly knowledge, recalls jump to over 50\%, with a moderate fall of precision. 
As a result, accuracies significantly increase. 

\subsubsection{Comparison to other RTE systems}

\begin{table}[t]
\centering
\footnotesize
\setlength{\tabcolsep}{4pt}
\begin{tabular}{| l | c c c c |}
\hline
 & RTE2 & RTE3 & RTE4 & RTE5 \\
\hline
Bos06 & 60.6 & - & - & - \\
MacCartney08 & - & 59.4 & - & - \\
Clark08 & - & - & 56.5 & - \\
Wang10 & \textbf{63.0} & 61.1 & - & - \\
Stern11 & 61.6 & \textbf{67.1} & - & 63.5 \\
Stern12 & - & - & - & 64.0 \\
Our Sys. & 58.8 & 63.0 & \textbf{59.6} & \textbf{65.8} \\
\hline
\end{tabular}
\caption{Comparison with other systems}
\label{tab:rtecompare}
\end{table}

A comparison between our system and other RTE systems is shown in Table~\ref{tab:rtecompare}. 
Bos06 \cite{bos06} is a hybrid system combining deep features from a theorem prover and a model 
builder, together with shallow features such as lexical overlap and text length. MacCartney08 
\cite{maccartney08} uses natural logic to calculate inference relations between two superficially 
aligned sentences. 
Clark08 \cite{clark08} is a logic-based system utilizing various resources including WordNet and 
DIRT paraphrases \cite{lin01}, and is tolerant to partially unproven {\bf H} sentences in some degree. 
All of the three systems pursue a logical approach, while combining various techniques to achieve robustness. 
The result shows that our system has comparable performance. On the other hand, Wang10 \cite{wang10} 
learns a tree-edit model from training data, and captures entailment relation by tree edit distance. 
Stern11 \cite{stern11} and Stern12 \cite{stern12} extend this framework to utilize entailment 
rules as tree transformations. These are more tailored systems using machine learning with many 
handcrafted features. Still, our unsupervised system outperforms the state-of-the-art on RTE5 dataset. 

\subsubsection{Analysis}

\begin{figure}[t]
\centering
\includegraphics[scale=0.60,bb=0 0 250 180,clip]{ontheflystat.pdf}
\caption{Proportion of proven pairs and their precision, w.r.t. pieces of on-the-fly 
knowledge.}
\label{fig:ontheflystat}
\end{figure}

Summing up test data from RTE2 to RTE5, Figure~\ref{fig:ontheflystat} shows the proportion of 
all proven pairs and their precision. Less than 5\% pairs can be proven primarily, 
with a precision of 77\%. Over 40\% 
pairs can be proven by one piece of on-the-fly knowledge, yet pairs do exist 
in which more than 2 pieces are necessary. 
The precisions of 1 and 2 pieces on-the-fly knowledge application are over 60\%, which is fairly 
high, given our rough estimation of the similarity score. As a comparison, 
\newcite{dinu09} studied the proportion of proven pairs 
and precision by applying DIRT rules to tree skeletons in RTE2 and RTE3 data. The proportion 
is 8\% with precision 65\% on RTE2, and proportion 6\% with precision 72\% on RTE3. Applied 
by our logical system, the noisy on-the-fly knowledge can achieve a precision comparable to higher 
quality resources such as DIRT.

A major type of error is caused by the ignorance of semantic roles in calculation of 
similarity scores. For example, though ``\textit{Italy beats Kazakhstan}" is not primarily proven 
from ``\textit{Italy is defeated by Kazakhstan}", our system does produce the path alignment 
``\texttt{SUBJ}(\textbf{beat})\texttt{OBJ} $\approx$ 
\texttt{OBJ}(\textbf{defeat})\texttt{SUBJ}'' with a high similarity score. 
The impact of such errors depends on the data making methodology, though. It lowers 
precisions in RTE2 and RTE3 data, particularly in ``IE'' subtask (where precisions drop under $0.5$). 
On the other hand, it occurs less often in ``IR'' subtask. 

Finally, to see if we ``get lucky" on RTE5 data in the choice of word vectors 
and thresholds, we change the thresholds from $0.1$ to $0.7$ and draw the precision-recall curve, 
using two types of word vectors, \textit{Mikolov13} and \textit{Turian10}. As shown in 
Figure~\ref{fig:precrec}, though the precision drops for \textit{Turian10}, both curves 
show the pattern that our system keeps gaining recall while maintaining precision to a certain level. 
Not too much ``magic" in \textit{Mikolov13} actually: for over 80\% pairs, every node in DCS 
tree of {\bf H} can be covered by a path of length $\leq 5$ 
that has a corresponding path of length $\leq 5$ in {\bf T} with a similarity score $>0.4$. 

\begin{figure}[t]
\centering
\includegraphics[scale=0.40,bb=0 0 500 240,clip]{precrec.pdf}
\caption{Precision-Recall curve.}
\label{fig:precrec}
\end{figure}



\section{Conclusion and Discussion}

We have presented a method of deriving abstract denotation from DCS trees, 
which enables logical inference on DCS, and we developed a textual inference
system based on the framework.
Experimental results have shown the power of the representation that allows
both strict inference as on FraCaS data and robust reasoning as on RTE data.

Exploration of an appropriate meaning representation 
for querying and reasoning on knowledge bases has a long history.
Description logic, being less expressive than FOL but featuring more efficient reasoning,
is used as a theory base for Semantic Web \cite{OWL}.
Ideas similar to our framework, including the 
use of sets in a representation that benefits efficient reasoning,
are also found in description logic and knowledge representation community \cite{Baader03,Sowa99,Sukkarieh03}. 
To our knowledge, however, their applications to logical inference beyond
the use for database querying have not been much explored in the context of NLP.

The pursue of a logic more suitable for natural language inference is not new.
For instance, \newcite{maccartney08} has implemented a model of natural logic \cite{lakoff70}.
While being computationally efficient, 
various inference patterns are out of the scope of their system.

Much work has been done in mapping natural language into database queries
\cite{cai-yates13,kwiatkowski13,poon13}.
Among these, the ($\lambda$-)DCS \cite{liang11,berant13} framework defines algorithms
that transparently map a labeled tree to a database querying procedure.
Essentially, this is because DCS trees restrict the querying process to
a very limited subset of possible operations. 
Our main contribution, the abstract denotation of DCS trees, can thus be considered as
an attempt to characterize a fragment of FOL that is suited for both natural language 
inference {\it and} transparent syntax-semantics mapping, through the choice of 
operations and relations on sets.

We have demonstrated the utility of logical inference on DCS through the RTE task.
A wide variety of strategies tackling the RTE task have been investigated 
\cite{rtesurvey}, including the 
comparison of surface strings \cite{jijkoun05}, syntactic and semantic structures \cite{haghighi05,snow06,zanzotto09,burchardt09,heilman10,wang10}, 
semantic vectors \cite{erk09} and logical representations \cite{bos05,raina05,tatu05}. 
Acquisition of basic knowledge for RTE is also a huge stream of research \cite{lin01,shinyama02,sudo03,szpektor04,fujita12,weisman12,yan13}.
These previous works include various techniques for acquiring and incorporating different kinds of 
linguistic and world knowledge, 
and further fight against the knowledge bottleneck problem, 
e.g. by back-off to shallower representations.

Logic-based RTE systems employ various approaches to bridge knowledge gaps. \newcite{bos05} proposes 
features from a model builder; \newcite{raina05} proposes an abduction process; 
\newcite{tatu06} shows handcrafted rules could drastically improve the performance of a 
logic-based RTE system. 

As such, our current RTE system is at a proof-of-concept stage, in that many of
the above techniques are yet to be implemented.
Nonetheless, we would like to emphasize that it already shows performance competitive to 
state-of-the-art systems on one data set (RTE5).
Other directions of our future work include further exploitation of the
new semantic representation.
For example, since abstract denotations are readily suited for data querying, they can be 
used to verify newly generated assumptions by fact search in a database. 
This may open a way towards a hybrid approach to RTE wherein logical inference is intermingled with 
large scale database querying.

\paragraph{Acknowledgments}
This research was supported by the Todai Robot Project at National
Institute of Informatics.

\bibliographystyle{acl}
\bibliography{rte}

\end{document}
