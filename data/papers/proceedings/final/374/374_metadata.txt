SubmissionNumber#=%=#374
FinalPaperTitle#=%=#A chance-corrected measure of inter-annotator agreement for syntax
ShortPaperTitle#=%=#A chance-corrected measure of inter-annotator agreement for syntax
NumberOfPages#=%=#11
CopyrightSigned#=%=#Arne Skjærholt
JobTitle#==#PhD Fellow
Organization#==#University of Oslo
Department of Informatics
PB 1080 Blindern
0316 OSLO
Norway
Abstract#==#Following the works of Carletta (1996)
and Artstein and Poesio (2008), there is an
increasing consensus within the field that
in order to properly gauge the reliability
of an annotation effort, chance-corrected
measures of inter-annotator agreement
should be used. With this in mind, it
is striking that virtually all evaluations
of syntactic annotation efforts use uncorrected parser evaluation metrics such
as
bracket F1 (for phrase structure) and accuracy scores (for dependencies).
In this work we present a chance-corrected
metric based on Krippendorff’s α, adapted
to the structure of syntactic annotations
and applicable both to phrase structure
and dependency annotation without any
modifications. To evaluate our metric we
first present a number of synthetic experiments
to better control the sources of noise
and gauge the metric’s responses, before
finally contrasting the behaviour of our
chance-corrected metric with that of uncorrected parser evaluation metrics on
real
corpora.
Author{1}{Firstname}#=%=#Arne
Author{1}{Lastname}#=%=#Skjærholt
Author{1}{Email}#=%=#arnskj@ifi.uio.no
Author{1}{Affiliation}#=%=#University of Oslo

==========