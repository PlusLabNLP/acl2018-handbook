SubmissionNumber#=%=#206
FinalPaperTitle#=%=#Learning Grounded Meaning Representations with Autoencoders
ShortPaperTitle#=%=#Learning Grounded Meaning Representations with Autoencoders
NumberOfPages#=%=#12
CopyrightSigned#=%=#Carina Silberer
JobTitle#==#
Organization#==#School of Informatics, University of Edinburgh
Abstract#==#In this paper we address the problem of grounding distributional
representations of lexical meaning. We introduce a new model which uses stacked
autoencoders to  learn higher-level embeddings from textual and visual input.
The two modalities 
are encoded as vectors of attributes and are obtained automatically from text 
and images, respectively. We evaluate our model on its ability to simulate 
similarity judgments and concept categorization. On both tasks, our approach 
outperforms baselines and related models.
Author{1}{Firstname}#=%=#Carina
Author{1}{Lastname}#=%=#Silberer
Author{1}{Email}#=%=#c.silberer@ed.ac.uk
Author{1}{Affiliation}#=%=#School of Informatics, University of Edinburgh
Author{2}{Firstname}#=%=#Mirella
Author{2}{Lastname}#=%=#Lapata
Author{2}{Email}#=%=#mlap@inf.ed.ac.uk
Author{2}{Affiliation}#=%=#School of Informatics, University of Edinburgh

==========