SubmissionNumber#=%=#548
FinalPaperTitle#=%=#Sparser, Better, Faster GPU Parsing
ShortPaperTitle#=%=#Sparser, Better, Faster GPU Parsing
NumberOfPages#=%=#10
CopyrightSigned#=%=#David Hall
JobTitle#==#
Organization#==#UC Berkeley EECS CS Division
374 Soda Hall
Berkeley, CA, USA 94720
Abstract#==#Due to their origin in computer graphics, graphics processing units (GPUs) are
highly optimized for dense problems, where the exact same operation is applied
repeatedly to all data points. Natural language processing algorithms, on the
other hand, are traditionally constructed in ways that exploit structural
sparsity. Recently, Canny et al. (2013) presented an approach to GPU parsing
that sacrifices traditional sparsity in exchange for raw computational power,
obtaining a system that can compute Viterbi parses for a high-quality grammar
at about 164 sentences per second on a mid-range GPU. In this work, we
reintroduce sparsity to GPU parsing by adapting a coarse-to-fine pruning
approach to the constraints of a GPU. The resulting system is capable of
computing over 404 Viterbi parses per second—more than a 2x speedup—on the
same hardware. Moreover, our approach allows us to efficiently implement less
GPU-friendly minimum Bayes risk inference, improving throughput for this more
accurate algorithm from only 32 sentences per second unpruned to over 190
sentences per second using pruning—nearly a 6x speedup.
Author{1}{Firstname}#=%=#David
Author{1}{Lastname}#=%=#Hall
Author{1}{Email}#=%=#dlwh@cs.berkeley.edu
Author{1}{Affiliation}#=%=#UC Berkeley
Author{2}{Firstname}#=%=#Taylor
Author{2}{Lastname}#=%=#Berg-Kirkpatrick
Author{2}{Email}#=%=#tberg@eecs.berkeley.edu
Author{2}{Affiliation}#=%=#UC Berkeley
Author{3}{Firstname}#=%=#Dan
Author{3}{Lastname}#=%=#Klein
Author{3}{Email}#=%=#klein@cs.berkeley.edu
Author{3}{Affiliation}#=%=#UC Berkeley

==========