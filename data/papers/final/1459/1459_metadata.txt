SubmissionNumber#=%=#1459
FinalPaperTitle#=%=#Learning Efficient Dialogue Policy from Demonstrations through Shaping
ShortPaperTitle#=%=#
NumberOfPages#=%=#11
CopyrightSigned#=%=#Baolin Peng
JobTitle#==#
Organization#==#Microsoft Research, Redmond, WA, USA
Abstract#==#Training a task-oriented dialogue agent with reinforcement learning is prohibitively expensive since it requires a large volume of interactions with users. Human demonstrations can be used to accelerate learning progress. However, how to effectively leverage demonstrations to learn dialogue policy remains less explored. In this paper, we present S{\^{}}2Agent that efficiently learns dialogue policy from demonstrations through policy shaping and reward shaping. We use an imitation model to distill knowledge from demonstrations, based on which policy shaping estimates feedback on how the agent should act in policy space. Reward shaping is then incorporated to bonus state-actions similar to demonstrations explicitly in value space encouraging better exploration. The effectiveness of the proposed S{\^{}}2Agentt is demonstrated in three dialogue domains and a challenging domain adaptation task with both user simulator evaluation and human evaluation.
Author{1}{Firstname}#=%=#Huimin
Author{1}{Lastname}#=%=#Wang
Author{1}{Username}#=%=#wanghm
Author{1}{Email}#=%=#wanghm520@gmail.com
Author{1}{Affiliation}#=%=#The Chinese University of Hong Kong
Author{2}{Firstname}#=%=#Baolin
Author{2}{Lastname}#=%=#Peng
Author{2}{Username}#=%=#blpeng
Author{2}{Email}#=%=#bapeng@microsoft.com
Author{2}{Affiliation}#=%=#Microsoft Research
Author{3}{Firstname}#=%=#Kam-Fai
Author{3}{Lastname}#=%=#Wong
Author{3}{Username}#=%=#kfwong
Author{3}{Email}#=%=#kfwong@se.cuhk.edu.hk
Author{3}{Affiliation}#=%=#Department of Systems Engineering and Engineering Management, The Chinese University of Hong Kong, Hong Kong

==========