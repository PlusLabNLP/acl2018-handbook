SubmissionNumber#=%=#817
FinalPaperTitle#=%=#Document Modeling with Graph Attention Networks for Multi-grained Machine Reading Comprehension
ShortPaperTitle#=%=#
NumberOfPages#=%=#11
CopyrightSigned#=%=#Bo Zheng
JobTitle#==#
Organization#==#Harbin Institute of Technology, No.92, Xidazhi Street, Nangang District, Harbin, China
Abstract#==#Natural Questions is a new challenging machine reading comprehension benchmark with two-grained answers, which are a long answer (typically a paragraph) and a short answer (one or more entities inside the long answer).  Despite the effectiveness of existing methods on this benchmark, they treat these two sub-tasks individually during training while ignoring their dependencies. To address this issue, we present a novel multi-grained machine reading comprehension framework that focuses on modeling documents at their hierarchical nature, which are different levels of granularity: documents, paragraphs, sentences, and tokens. We utilize graph attention networks to obtain different levels of representations so that they can be learned simultaneously. The long and short answers can be extracted from paragraph-level representation and token-level representation, respectively. In this way, we can model the dependencies between the two-grained answers to provide evidence for each other. We jointly train the two sub-tasks, and our experiments show that our approach significantly outperforms previous systems at both long and short answer criteria.
Author{1}{Firstname}#=%=#Bo
Author{1}{Lastname}#=%=#Zheng
Author{1}{Username}#=%=#bzheng
Author{1}{Email}#=%=#dsoul0621@gmail.com
Author{1}{Affiliation}#=%=#Harbin institute of technology
Author{2}{Firstname}#=%=#Haoyang
Author{2}{Lastname}#=%=#Wen
Author{2}{Username}#=%=#hywen
Author{2}{Email}#=%=#wen17@illinois.edu
Author{2}{Affiliation}#=%=#University of Illinois at Urbana-Champaign
Author{3}{Firstname}#=%=#Yaobo
Author{3}{Lastname}#=%=#Liang
Author{3}{Username}#=%=#eurekaliang
Author{3}{Email}#=%=#yalia@microsoft.com
Author{3}{Affiliation}#=%=#microsoft.com
Author{4}{Firstname}#=%=#Nan
Author{4}{Lastname}#=%=#Duan
Author{4}{Username}#=%=#nanduan
Author{4}{Email}#=%=#nanduan@microsoft.com
Author{4}{Affiliation}#=%=#Microsoft Research Asia
Author{5}{Firstname}#=%=#Wanxiang
Author{5}{Lastname}#=%=#Che
Author{5}{Username}#=%=#wanxiang
Author{5}{Email}#=%=#wanxiang@gmail.com
Author{5}{Affiliation}#=%=#Harbin Institute of Technology
Author{6}{Firstname}#=%=#Daxin
Author{6}{Lastname}#=%=#Jiang
Author{6}{Username}#=%=#djiang
Author{6}{Email}#=%=#djiang@microsoft.com
Author{6}{Affiliation}#=%=#STCA NLP Group, Microsoft
Author{7}{Firstname}#=%=#Ming
Author{7}{Lastname}#=%=#Zhou
Author{7}{Username}#=%=#mingzhou
Author{7}{Email}#=%=#mingzhou@microsoft.com
Author{7}{Affiliation}#=%=#microsoft research asia
Author{8}{Firstname}#=%=#Ting
Author{8}{Lastname}#=%=#Liu
Author{8}{Username}#=%=#tliu72
Author{8}{Email}#=%=#tliu72@qq.com
Author{8}{Affiliation}#=%=#Harbin Institute of Technology

==========