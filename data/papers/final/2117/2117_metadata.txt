SubmissionNumber#=%=#2117
FinalPaperTitle#=%=#BLEURT: Learning Robust Metrics for Text Generation
ShortPaperTitle#=%=#
NumberOfPages#=%=#12
CopyrightSigned#=%=#Thibault Sellam
JobTitle#==#
Organization#==#Google
Abstract#==#Text generation has made significant advances in the last few years. Yet, evaluation metrics have lagged behind, as the most popular choices (e.g., BLEU and ROUGE) may correlate poorly with human judgment. We propose BLEURT, a learned evaluation metric for English based on BERT. BLEURT can model human judgment with a few thousand possibly biased training examples. A key aspect of our approach is a novel pre-training scheme that uses millions of synthetic examples to help the model generalize. BLEURT provides state-of-the-art results on the last three years of the WMT Metrics shared task and the WebNLG data set. In contrast to a vanilla BERT-based approach, it yields superior results even when the training data is scarce and out-of-distribution.
Author{1}{Firstname}#=%=#Thibault
Author{1}{Lastname}#=%=#Sellam
Author{1}{Username}#=%=#tsellam
Author{1}{Email}#=%=#tsellam@google.com
Author{1}{Affiliation}#=%=#Google
Author{2}{Firstname}#=%=#Dipanjan
Author{2}{Lastname}#=%=#Das
Author{2}{Username}#=%=#dipanjand
Author{2}{Email}#=%=#dipanjand@gmail.com
Author{2}{Affiliation}#=%=#Google AI Language
Author{3}{Firstname}#=%=#Ankur
Author{3}{Lastname}#=%=#Parikh
Author{3}{Username}#=%=#aparikh
Author{3}{Email}#=%=#aparikh@google.com
Author{3}{Affiliation}#=%=#Google

==========