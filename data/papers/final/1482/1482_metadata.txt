SubmissionNumber#=%=#1482
FinalPaperTitle#=%=#A Generative Model for Joint Natural Language Understanding and Generation
ShortPaperTitle#=%=#
NumberOfPages#=%=#13
CopyrightSigned#=%=#Bo-Hsiang Tseng
JobTitle#==#
Organization#==#Bo-Hsiang Tseng
Abstract#==#Natural language understanding (NLU) and natural language generation (NLG) are two fundamental and related tasks in building task-oriented dialogue systems with opposite objectives: NLU tackles the transformation from natural language to formal representations, whereas NLG does the reverse. A key to success in either task is parallel training data which is expensive to obtain at a large scale. In this work, we propose a generative model which couples NLU and NLG through a shared latent variable. This approach allows us to explore both spaces of natural language and formal representations, and facilitates information sharing through the latent space to eventually benefit NLU and NLG. Our model achieves state-of-the-art performance on two dialogue datasets with both flat and tree-structured formal representations. We also show that the model can be trained in a semi-supervised fashion by utilising unlabelled data to boost its performance.
Author{1}{Firstname}#=%=#Bo-Hsiang
Author{1}{Lastname}#=%=#Tseng
Author{1}{Username}#=%=#andy194673
Author{1}{Email}#=%=#bht26@cam.ac.uk
Author{1}{Affiliation}#=%=#University of Cambridge
Author{2}{Firstname}#=%=#Jianpeng
Author{2}{Lastname}#=%=#Cheng
Author{2}{Username}#=%=#cheng6076
Author{2}{Email}#=%=#cheng6076@gmail.com
Author{2}{Affiliation}#=%=#Apple
Author{3}{Firstname}#=%=#Yimai
Author{3}{Lastname}#=%=#Fang
Author{3}{Username}#=%=#yfang
Author{3}{Email}#=%=#yimai_fang@apple.com
Author{3}{Affiliation}#=%=#Apple
Author{4}{Firstname}#=%=#David
Author{4}{Lastname}#=%=#Vandyke
Author{4}{Username}#=%=#vandykeuc
Author{4}{Email}#=%=#vandyke.d@gmail.com
Author{4}{Affiliation}#=%=#Apple

==========