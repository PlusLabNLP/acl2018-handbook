SubmissionNumber#=%=#1941
FinalPaperTitle#=%=#Multi-source Meta Transfer for Low Resource Multiple-Choice Question Answering
ShortPaperTitle#=%=#
NumberOfPages#=%=#11
CopyrightSigned#=%=#Ming Yan
JobTitle#==#
Organization#==#Institute of High Performance Computing, A*STAR, Singapore
Abstract#==#Multiple-choice question answering (MCQA) is one of the most challenging tasks in machine reading comprehension since it requires more advanced reading comprehension skills such as logical reasoning, summarization, and arithmetic operations. Unfortunately, most existing MCQA datasets are small in size, which increases the difficulty of model learning and generalization. To address this challenge, we propose a multi-source meta transfer (MMT) for low-resource MCQA. In this framework,  we first extend meta learning by incorporating multiple training sources to learn a generalized feature representation across domains. To bridge the distribution gap between training sources and the target, we further introduce the meta transfer that can be integrated into the multi-source meta training. More importantly, the proposed MMT is independent of backbone language models. Extensive experiments demonstrate the superiority of MMT over state-of-the-arts, and continuous improvements can be achieved on different backbone networks on both supervised and unsupervised domain adaptation settings.
Author{1}{Firstname}#=%=#Ming
Author{1}{Lastname}#=%=#Yan
Author{1}{Username}#=%=#mingtop
Author{1}{Email}#=%=#yan_ming@ihpc.a-star.edu.sg
Author{1}{Affiliation}#=%=#Institute of High Performance Computing
Author{2}{Firstname}#=%=#Hao
Author{2}{Lastname}#=%=#Zhang
Author{2}{Username}#=%=#isaacchanghau
Author{2}{Email}#=%=#isaac.changhau@gmail.com
Author{2}{Affiliation}#=%=#Agency for Science, Technology and Research
Author{3}{Firstname}#=%=#Di
Author{3}{Lastname}#=%=#Jin
Author{3}{Username}#=%=#jindi
Author{3}{Email}#=%=#jindi15@mit.edu
Author{3}{Affiliation}#=%=#MIT
Author{4}{Firstname}#=%=#Joey Tianyi
Author{4}{Lastname}#=%=#Zhou
Author{4}{Username}#=%=#joeyzhouty
Author{4}{Email}#=%=#joey.tianyi.zhou@gmail.com
Author{4}{Affiliation}#=%=#Institute of High Performance Computing

==========