SubmissionNumber#=%=#1065
FinalPaperTitle#=%=#Do you have the right scissors? Tailoring Pre-trained Language Models via Monte-Carlo Methods
ShortPaperTitle#=%=#
NumberOfPages#=%=#6
CopyrightSigned#=%=#NING MIAO
JobTitle#==#
Organization#==#ByteDance AI-Lab. Taipeng building, Haidian District, Beijing, China
Abstract#==#It has been a common approach to pre-train a language model on a large corpus and fine-tune it on task-specific data. 
In practice, we observe that fine-tuning a pre-trained model on a small dataset may lead to over- and/or under-estimate problem. 
In this paper, we propose MC-Tailor, a novel method to alleviate the above issue in text generation tasks by truncating and transferring the probability mass from over-estimated regions to under-estimated ones. 
Experiments on a variety of text generation datasets show that MC-Tailor consistently and significantly outperforms the fine-tuning approach.
Author{1}{Firstname}#=%=#Ning
Author{1}{Lastname}#=%=#Miao
Author{1}{Username}#=%=#miaoning
Author{1}{Email}#=%=#miaoning@bytedance.com
Author{1}{Affiliation}#=%=#ByteDance
Author{2}{Firstname}#=%=#Yuxuan
Author{2}{Lastname}#=%=#Song
Author{2}{Username}#=%=#songyuxuan
Author{2}{Email}#=%=#yxsong0816@gmail.com
Author{2}{Affiliation}#=%=#Shanghai Jiao Tong University
Author{3}{Firstname}#=%=#Hao
Author{3}{Lastname}#=%=#Zhou
Author{3}{Username}#=%=#wazwy
Author{3}{Email}#=%=#zhouhao.nlp@bytedance.com
Author{3}{Affiliation}#=%=#Bytedance AI Lab
Author{4}{Firstname}#=%=#Lei
Author{4}{Lastname}#=%=#Li
Author{4}{Username}#=%=#leili
Author{4}{Email}#=%=#lileilab@bytedance.com
Author{4}{Affiliation}#=%=#Bytedance AI Lab

==========