SubmissionNumber#=%=#2582
FinalPaperTitle#=%=#Dynamic Sampling Strategies for Multi-Task Reading Comprehension
ShortPaperTitle#=%=#
NumberOfPages#=%=#5
CopyrightSigned#=%=#Ananth Gottumukkala
JobTitle#==#
Organization#==#University of California, Irvine
Abstract#==#Building general reading comprehension systems, capable of solving multiple datasets at the same time, is a recent aspirational goal in the research community. Prior work has focused on model architecture or generalization to held out datasets, and largely passed over the particulars of the multi-task learning set up. We show that a simple dynamic sampling strategy, selecting instances for training proportional to the multi-task model's current performance on a dataset relative to its single task performance, gives substantive gains over prior multi-task sampling strategies, mitigating the catastrophic forgetting that is common in multi-task learning. We also demonstrate that allowing instances of different tasks to be interleaved as much as possible between each epoch and batch has a clear beneﬁt in multitask performance over forcing task homogeneity at the epoch or batch level. Our ﬁnal model shows greatly increased performance over the best model on ORB, a recently-released multitask reading comprehension benchmark.
Author{1}{Firstname}#=%=#Ananth
Author{1}{Lastname}#=%=#Gottumukkala
Author{1}{Username}#=%=#agottumu
Author{1}{Email}#=%=#superanth1000@gmail.com
Author{1}{Affiliation}#=%=#UC Irvine
Author{2}{Firstname}#=%=#Dheeru
Author{2}{Lastname}#=%=#Dua
Author{2}{Username}#=%=#ddua
Author{2}{Email}#=%=#dheeru_dua@hotmail.com
Author{2}{Affiliation}#=%=#University of California, Irvine
Author{3}{Firstname}#=%=#Sameer
Author{3}{Lastname}#=%=#Singh
Author{3}{Username}#=%=#sameer
Author{3}{Email}#=%=#sameer@uci.edu
Author{3}{Affiliation}#=%=#University of California, Irvine
Author{4}{Firstname}#=%=#Matt
Author{4}{Lastname}#=%=#Gardner
Author{4}{Username}#=%=#mattg
Author{4}{Email}#=%=#mattg@allenai.org
Author{4}{Affiliation}#=%=#Allen Institute for Artificial Intelligence

==========