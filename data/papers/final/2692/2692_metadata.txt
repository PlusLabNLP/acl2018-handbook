SubmissionNumber#=%=#2692
FinalPaperTitle#=%=#Multi-agent Communication meets Natural Language: Synergies between Functional and Structural Language Learning
ShortPaperTitle#=%=#
NumberOfPages#=%=#12
CopyrightSigned#=%=#Angeliki Lazaridou
JobTitle#==#
Organization#==#DeepMind, 6 Pancras Square, N1C 4AG
Abstract#==#We present a method for combining multi-agent communication and traditional data-driven approaches to natural language learning, with an end goal of teaching agents to communicate with humans in natural language.  Our starting point is a language model that has been trained on generic, not task-specific language data. We then place this model in a multi-agent self-play environment that generates task-specific rewards used to adapt or modulate the model, turning it into a task-conditional language model. We introduce a new way for combining the two types of learning based on the idea of reranking language model samples, and show that this method outperforms others in communicating with humans in a visual referential communication task. Finally, we present a taxonomy of different types of language drift that can occur alongside a set of measures to detect them.
Author{1}{Firstname}#=%=#Angeliki
Author{1}{Lastname}#=%=#Lazaridou
Author{1}{Username}#=%=#angeliki
Author{1}{Email}#=%=#angeliki@google.com
Author{1}{Affiliation}#=%=#DeepMind
Author{2}{Firstname}#=%=#Anna
Author{2}{Lastname}#=%=#Potapenko
Author{2}{Username}#=%=#annapotapenko
Author{2}{Email}#=%=#apotapenko@google.com
Author{2}{Affiliation}#=%=#DeepMind
Author{3}{Firstname}#=%=#Olivier
Author{3}{Lastname}#=%=#Tieleman
Author{3}{Username}#=%=#otieleman
Author{3}{Email}#=%=#tieleman@google.com
Author{3}{Affiliation}#=%=#DeepMind

==========