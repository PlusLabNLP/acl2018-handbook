SubmissionNumber#=%=#2972
FinalPaperTitle#=%=#Continual Relation Learning via Episodic Memory Activation and Reconsolidation
ShortPaperTitle#=%=#
NumberOfPages#=%=#12
CopyrightSigned#=%=#Xu Han
JobTitle#==#
Organization#==#Tsinghua University
Abstract#==#Continual relation learning aims to continually train a model on new data to learn incessantly emerging novel relations while avoiding catastrophically forgetting old relations. Some pioneering work has proved that storing a handful of historical relation examples in episodic memory and replaying them in subsequent training is an effective solution for such a challenging problem. However, these memory-based methods usually suffer from overfitting the few memorized examples of old relations, which may gradually cause inevitable confusion among existing relations. Inspired by the mechanism in human long-term memory formation, we introduce episodic memory activation and reconsolidation (EMAR) to continual relation learning. Every time neural models are activated to learn both new and memorized data, EMAR utilizes relation prototypes for memory reconsolidation exercise to keep a stable understanding of old relations. The experimental results show that EMAR could get rid of catastrophically forgetting old relations and outperform the state-of-the-art continual learning models.
Author{1}{Firstname}#=%=#Xu
Author{1}{Lastname}#=%=#Han
Author{1}{Username}#=%=#thu.hanxu13
Author{1}{Email}#=%=#thu.hanxu13@gmail.com
Author{1}{Affiliation}#=%=#Tsinghua University
Author{2}{Firstname}#=%=#Yi
Author{2}{Lastname}#=%=#Dai
Author{2}{Username}#=%=#daiy17
Author{2}{Email}#=%=#daiy17@mails.tsinghua.edu.cn
Author{2}{Affiliation}#=%=#Tsinghua University
Author{3}{Firstname}#=%=#Tianyu
Author{3}{Lastname}#=%=#Gao
Author{3}{Username}#=%=#gaotianyu1350
Author{3}{Email}#=%=#gty16@mails.tsinghua.edu.cn
Author{3}{Affiliation}#=%=#Tsinghua University
Author{4}{Firstname}#=%=#Yankai
Author{4}{Lastname}#=%=#Lin
Author{4}{Username}#=%=#lyk423
Author{4}{Email}#=%=#yankailin@tencent.com
Author{4}{Affiliation}#=%=#Pattern Recognition Center, WeChat, Tencent
Author{5}{Firstname}#=%=#Zhiyuan
Author{5}{Lastname}#=%=#Liu
Author{5}{Username}#=%=#lzy.thu
Author{5}{Email}#=%=#liuzy@tsinghua.edu.cn
Author{5}{Affiliation}#=%=#Tsinghua University
Author{6}{Firstname}#=%=#Peng
Author{6}{Lastname}#=%=#Li
Author{6}{Username}#=%=#lipeng17
Author{6}{Email}#=%=#patrickpli@tencent.com
Author{6}{Affiliation}#=%=#WeChat AI, Tencent Inc., China
Author{7}{Firstname}#=%=#Maosong
Author{7}{Lastname}#=%=#Sun
Author{7}{Username}#=%=#sms
Author{7}{Email}#=%=#sms@tsinghua.edu.cn
Author{7}{Affiliation}#=%=#Tsinghua University
Author{8}{Firstname}#=%=#Jie
Author{8}{Lastname}#=%=#Zhou
Author{8}{Username}#=%=#jerryitp
Author{8}{Email}#=%=#withtomzhou@tencent.com
Author{8}{Affiliation}#=%=#Tencent Inc.

==========