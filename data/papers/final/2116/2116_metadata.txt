SubmissionNumber#=%=#2116
FinalPaperTitle#=%=#Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation
ShortPaperTitle#=%=#
NumberOfPages#=%=#11
CopyrightSigned#=%=#Chao Zhao
JobTitle#==#
Organization#==#UNC Chapel Hill
Abstract#==#Generating sequential natural language descriptions from graph-structured data (e.g., knowledge graph) is challenging, partly because of the structural differences between the input graph and the output text. Hence, popular sequence-to-sequence models, which require serialized input, are not a natural fit for this task. Graph neural networks, on the other hand, can better encode the input graph but broaden the structural gap between the encoder and decoder, making faithful generation difficult. To narrow this gap, we propose DualEnc, a dual encoding model that can not only incorporate the graph structure, but can also cater to the linear structure of the output text. Empirical comparisons with strong single-encoder baselines demonstrate that dual encoding can significantly improve the quality of the generated text.
Author{1}{Firstname}#=%=#Chao
Author{1}{Lastname}#=%=#Zhao
Author{1}{Username}#=%=#zhaochaocs
Author{1}{Email}#=%=#zhaochaocs@gmail.com
Author{1}{Affiliation}#=%=#University of North Carolina at Chapel Hill
Author{2}{Firstname}#=%=#Marilyn
Author{2}{Lastname}#=%=#Walker
Author{2}{Username}#=%=#maw
Author{2}{Email}#=%=#maw@soe.ucsc.edu
Author{2}{Affiliation}#=%=#University of California Santa Cruz
Author{3}{Firstname}#=%=#Snigdha
Author{3}{Lastname}#=%=#Chaturvedi
Author{3}{Username}#=%=#snigdha
Author{3}{Email}#=%=#snigdhac@gmail.com
Author{3}{Affiliation}#=%=#University of North Carolina, Chapel Hill

==========