SubmissionNumber#=%=#2849
FinalPaperTitle#=%=#A Comprehensive Analysis of Preprocessing for Word Representation Learning in Affective Tasks
ShortPaperTitle#=%=#
NumberOfPages#=%=#12
CopyrightSigned#=%=#Nastaran Babanejad
JobTitle#==#Ph.D Candidate
Organization#==#York University, Toronto, Canada
Abstract#==#Affective tasks such as sentiment analysis, emotion classification, and sarcasm detection have been popular in recent years due to an abundance of user-generated data, accurate computational linguistic models, and a broad range of relevant applications in various domains. At the same time, many studies have highlighted the importance of text preprocessing, as an integral step to any natural language processing prediction model and downstream task. While preprocessing in affective systems is well-studied, preprocessing in word vector-based models applied to affective systems, is not. To address this limitation, we conduct a comprehensive analysis of the role of preprocessing techniques in affective analysis based on word vector models. Our analysis is the first of its kind and provides useful insights of the importance of each preprocessing technique when applied at the training phase, commonly ignored in pretrained word vector models, and/or at the downstream task phase.
Author{1}{Firstname}#=%=#Nastaran
Author{1}{Lastname}#=%=#Babanejad
Author{1}{Username}#=%=#nastaran
Author{1}{Email}#=%=#nasba@cse.yorku.ca
Author{1}{Affiliation}#=%=#York University of Canada
Author{2}{Firstname}#=%=#Ameeta
Author{2}{Lastname}#=%=#Agrawal
Author{2}{Username}#=%=#ameeta
Author{2}{Email}#=%=#ameeta@eecs.yorku.ca
Author{2}{Affiliation}#=%=#York University
Author{3}{Firstname}#=%=#Aijun
Author{3}{Lastname}#=%=#An
Author{3}{Username}#=%=#aan
Author{3}{Email}#=%=#aan@cse.yorku.ca
Author{3}{Affiliation}#=%=#York University
Author{4}{Firstname}#=%=#Manos
Author{4}{Lastname}#=%=#Papagelis
Author{4}{Username}#=%=#papaggel
Author{4}{Email}#=%=#papaggel@eecs.yorku.ca
Author{4}{Affiliation}#=%=#York University

==========