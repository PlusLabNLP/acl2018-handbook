SubmissionNumber#=%=#1723
FinalPaperTitle#=%=#Sentence Meta-Embeddings for Unsupervised Semantic Textual Similarity
ShortPaperTitle#=%=#
NumberOfPages#=%=#8
CopyrightSigned#=%=#Nina Poerner
JobTitle#==#
Organization#==#LMU Munich
Abstract#==#We address the task of unsupervised Semantic Textual Similarity (STS) by ensembling diverse pre-trained sentence encoders into sentence meta-embeddings. We apply, extend and evaluate different meta-embedding methods from the word embedding literature at the sentence level, including dimensionality reduction (Yin and Schütze, 2016), generalized Canonical Correlation Analysis (Rastogi et al., 2015) and cross-view auto-encoders (Bollegala and Bao, 2018). Our sentence meta-embeddings set a new unsupervised State of The Art (SoTA) on the STS Benchmark and on the STS12-STS16 datasets, with gains of between 3.7% and 6.4% Pearson’s r over single-source systems.
Author{1}{Firstname}#=%=#Nina
Author{1}{Lastname}#=%=#Poerner
Author{1}{Username}#=%=#npoe
Author{1}{Email}#=%=#poerner@cis.uni-muenchen.de
Author{1}{Affiliation}#=%=#Center for Information and Language Processing, University of Munich
Author{2}{Firstname}#=%=#Ulli
Author{2}{Lastname}#=%=#Waltinger
Author{2}{Username}#=%=#ulliwaltinger
Author{2}{Email}#=%=#ulli.waltinger@siemens.com
Author{2}{Affiliation}#=%=#Siemens AG
Author{3}{Firstname}#=%=#Hinrich
Author{3}{Lastname}#=%=#Schütze
Author{3}{Username}#=%=#cislmu
Author{3}{Email}#=%=#inquiries@cislmu.org
Author{3}{Affiliation}#=%=#Center for Information and Language Processing, University of Munich

==========