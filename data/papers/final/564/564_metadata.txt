SubmissionNumber#=%=#564
FinalPaperTitle#=%=#Max-Margin Incremental CCG Parsing
ShortPaperTitle#=%=#
NumberOfPages#=%=#12
CopyrightSigned#=%=#Milos Stanojevic
JobTitle#==#
Organization#==#University of Edinburgh
Abstract#==#Incremental syntactic parsing has been an active research area both for cognitive scientists trying to model human sentence processing and for NLP researchers attempting to combine incremental parsing with language modelling for ASR and MT.  Most effort has   been directed at designing the right transition mechanism, but less has been done to answer the question of what a probabilistic model for those transition parsers should look like.

A very incremental transition mechanism of a recently proposed CCG parser when trained in straightforward locally normalised discriminative fashion produces very bad results on English CCGbank. We identify three biases as the causes of this problem: label bias, exposure bias and imbalanced probabilities bias.

While known techniques for tackling these biases improve results, they still do not make the parser state of the art. Instead, we tackle all of these three biases at the same time using an improved version of beam search optimisation that minimises all beam search violations instead of minimising only the biggest violation. The new incremental parser gives better results than all previously published incremental CCG parsers, and outperforms even some widely used non-incremental CCG parsers.
Author{1}{Firstname}#=%=#Miloš
Author{1}{Lastname}#=%=#Stanojević
Author{1}{Username}#=%=#m.stanojevic
Author{1}{Email}#=%=#milosh.stanojevic@gmail.com
Author{1}{Affiliation}#=%=#University of Edinburgh
Author{2}{Firstname}#=%=#Mark
Author{2}{Lastname}#=%=#Steedman
Author{2}{Username}#=%=#steedman
Author{2}{Email}#=%=#steedman@inf.ed.ac.uk
Author{2}{Affiliation}#=%=#University of Edinburgh

==========