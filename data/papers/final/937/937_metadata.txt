SubmissionNumber#=%=#937
FinalPaperTitle#=%=#SentiBERT: A Transferable Transformer-Based Architecture for Compositional Sentiment Semantics
ShortPaperTitle#=%=#
NumberOfPages#=%=#12
CopyrightSigned#=%=#Da Yin
JobTitle#==#
Organization#==#Peking University, No.5 Yiheyuan Road, Haidian District, Beijing, China
Abstract#==#We propose SentiBERT, a variant of BERT that effectively captures compositional sentiment semantics. 
The model incorporates contextualized representation with binary constituency parse tree to capture semantic composition. Comprehensive experiments demonstrate that SentiBERT achieves competitive performance on phrase-level sentiment classification. We further demonstrate that the sentiment composition learned from the phrase-level annotations on SST can be transferred to other sentiment analysis tasks as well as related tasks, such as emotion classification tasks. Moreover, we conduct ablation studies and design visualization methods to understand SentiBERT. We show that SentiBERT is better than baseline approaches in capturing negation and the contrastive relation and model the compositional sentiment semantics.
Author{1}{Firstname}#=%=#Da
Author{1}{Lastname}#=%=#Yin
Author{1}{Username}#=%=#wade_yin
Author{1}{Email}#=%=#wade_yin9712@pku.edu.cn
Author{1}{Affiliation}#=%=#Peking University
Author{2}{Firstname}#=%=#Tao
Author{2}{Lastname}#=%=#Meng
Author{2}{Username}#=%=#somethree
Author{2}{Email}#=%=#tmeng@cs.ucla.edu
Author{2}{Affiliation}#=%=#UCLA
Author{3}{Firstname}#=%=#Kai-Wei
Author{3}{Lastname}#=%=#Chang
Author{3}{Username}#=%=#kchang10
Author{3}{Email}#=%=#kw@kwchang.net
Author{3}{Affiliation}#=%=#UCLA

==========