SubmissionNumber#=%=#2572
FinalPaperTitle#=%=#Phone Features Improve Speech Translation
ShortPaperTitle#=%=#
NumberOfPages#=%=#10
CopyrightSigned#=%=#Elizabeth Salesky
JobTitle#==#
Organization#==#Johns Hopkins University, Baltimore, MD USA
Abstract#==#End-to-end models for speech translation (ST) more tightly couple speech recognition (ASR) and machine translation (MT) than a traditional cascade of separate ASR and MT models, with simpler model architectures and the potential for reduced error propagation. 
Their performance is often assumed to be superior, though in many conditions this is not yet the case. 
We compare cascaded and end-to-end models across high, medium, and low-resource conditions, and show that cascades remain stronger baselines. 
Further, we introduce two methods to incorporate phone features into ST models. 
We show that these features improve both architectures, closing the gap between end-to-end models and cascades, and outperforming previous academic work -- by up to 9 BLEU on our low-resource setting.
Author{1}{Firstname}#=%=#Elizabeth
Author{1}{Lastname}#=%=#Salesky
Author{1}{Username}#=%=#esalesky
Author{1}{Email}#=%=#elizabeth.salesky@gmail.com
Author{1}{Affiliation}#=%=#Johns Hopkins University
Author{2}{Firstname}#=%=#Alan W
Author{2}{Lastname}#=%=#Black
Author{2}{Username}#=%=#awbcmu
Author{2}{Email}#=%=#awb@cs.cmu.edu
Author{2}{Affiliation}#=%=#Carnegie Mellon University

==========