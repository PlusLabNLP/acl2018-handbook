SubmissionNumber#=%=#1050
FinalPaperTitle#=%=#Mitigating Gender Bias Amplification in Distribution by Posterior Regularization
ShortPaperTitle#=%=#
NumberOfPages#=%=#7
CopyrightSigned#=%=#Tao Meng
JobTitle#==#
Organization#==#University of California, Los Angeles
Abstract#==#Advanced machine learning techniques have boosted the performance of natural language processing. Nevertheless, recent studies, e.g., (CITATION) show that these techniques inadvertently capture the societal bias hidden in the corpus and further amplify it. However, their analysis is conducted only on models' top predictions. In this paper, we investigate the gender bias amplification issue from the distribution perspective and demonstrate that the bias is amplified in the view of predicted probability distribution over labels. We further propose a bias mitigation approach based on posterior regularization. With little performance loss, our method can almost remove the bias amplification in the distribution. Our study sheds the light on understanding the bias amplification.
Author{1}{Firstname}#=%=#Shengyu
Author{1}{Lastname}#=%=#Jia
Author{1}{Username}#=%=#jiasy16
Author{1}{Email}#=%=#jiasy16@mails.tsinghua.edu.cn
Author{1}{Affiliation}#=%=#Tsinghua University
Author{2}{Firstname}#=%=#Tao
Author{2}{Lastname}#=%=#Meng
Author{2}{Username}#=%=#somethree
Author{2}{Email}#=%=#tmeng@cs.ucla.edu
Author{2}{Affiliation}#=%=#UCLA
Author{3}{Firstname}#=%=#Jieyu
Author{3}{Lastname}#=%=#Zhao
Author{3}{Username}#=%=#jieyuzh
Author{3}{Email}#=%=#jyzhao@cs.ucla.edu
Author{3}{Affiliation}#=%=#University of California, Los Angeles
Author{4}{Firstname}#=%=#Kai-Wei
Author{4}{Lastname}#=%=#Chang
Author{4}{Username}#=%=#kchang10
Author{4}{Email}#=%=#kw@kwchang.net
Author{4}{Affiliation}#=%=#UCLA

==========