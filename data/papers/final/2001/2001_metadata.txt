SubmissionNumber#=%=#2001
FinalPaperTitle#=%=#Distilling Knowledge Learned in BERT for Text Generation
ShortPaperTitle#=%=#
NumberOfPages#=%=#13
CopyrightSigned#=%=#Yen-Chun Chen
JobTitle#==#
Organization#==#Microsoft Dynamics 365 AI Research
Abstract#==#Large-scale pre-trained language model such as BERT has achieved great success in language understanding tasks. However, it remains an open question how to utilize BERT for language generation. In this paper, we present a novel approach, Conditional Masked Language Modeling (C-MLM), to enable the finetuning of BERT on target generation tasks. The finetuned BERT (teacher) is exploited as extra supervision to improve conventional Seq2Seq models (student) for better text generation performance. By leveraging BERT's idiosyncratic bidirectional nature, distilling knowledge learned in BERT can encourage auto-regressive Seq2Seq models to plan ahead, imposing global sequence-level supervision for coherent text generation. Experiments show that the proposed approach significantly outperforms strong Transformer baselines on multiple language generation tasks such as machine translation and text summarization. Our proposed model also achieves new state of the art on IWSLT German-English and English-Vietnamese MT datasets.
Author{1}{Firstname}#=%=#Yen-Chun
Author{1}{Lastname}#=%=#Chen
Author{1}{Username}#=%=#yenchun
Author{1}{Email}#=%=#Yen-Chun.Chen@microsoft.com
Author{1}{Affiliation}#=%=#Microsoft Dynamics 365 AI Research
Author{2}{Firstname}#=%=#Zhe
Author{2}{Lastname}#=%=#Gan
Author{2}{Username}#=%=#zhegan27
Author{2}{Email}#=%=#zhe.gan@microsoft.com
Author{2}{Affiliation}#=%=#Microsoft
Author{3}{Firstname}#=%=#Yu
Author{3}{Lastname}#=%=#Cheng
Author{3}{Username}#=%=#ych.thu
Author{3}{Email}#=%=#yu.cheng@microsoft.com
Author{3}{Affiliation}#=%=#Microsoft
Author{4}{Firstname}#=%=#Jingzhou
Author{4}{Lastname}#=%=#Liu
Author{4}{Username}#=%=#liujingzhou
Author{4}{Email}#=%=#liujingzhou@cs.cmu.edu
Author{4}{Affiliation}#=%=#Carnegie Mellon University
Author{5}{Firstname}#=%=#Jingjing
Author{5}{Lastname}#=%=#Liu
Author{5}{Username}#=%=#jingl
Author{5}{Email}#=%=#jingl@csail.mit.edu
Author{5}{Affiliation}#=%=#Microsoft

==========