SubmissionNumber#=%=#1045
FinalPaperTitle#=%=#Automatic Detection of Generated Text is Easiest when Humans are Fooled
ShortPaperTitle#=%=#
NumberOfPages#=%=#15
CopyrightSigned#=%=#Daphne Ippolito
JobTitle#==#
Organization#==#University of Pennsylvania, 220 S 33rd St, Philadelphia, PA 19104, United States
Abstract#==#Recent advancements in neural language modelling make it possible to rapidly generate vast amounts of human-sounding text.
The capabilities of humans and automatic discriminators to detect machine-generated text have been a large source of research interest, but humans and machines rely on different cues to make their decisions.
Here, we perform careful benchmarking and analysis of three popular sampling-based decoding strategies---top-_k_, nucleus sampling, and untruncated random sampling---and show that improvements in decoding methods have primarily optimized for fooling humans.
This comes at the expense of introducing statistical abnormalities that make detection easy for automatic systems.
We also show that though both human and automatic detector performance improve with longer excerpt length, even multi-sentence excerpts can fool expert human raters over 30\% of the time.
Our findings reveal the importance of using both human and automatic detectors to assess the humanness of text generation systems.
Author{1}{Firstname}#=%=#Daphne
Author{1}{Lastname}#=%=#Ippolito
Author{1}{Username}#=%=#daphnei
Author{1}{Email}#=%=#daphnei@seas.upenn.edu
Author{1}{Affiliation}#=%=#University of Pennsylvania
Author{2}{Firstname}#=%=#Daniel
Author{2}{Lastname}#=%=#Duckworth
Author{2}{Username}#=%=#duckworthd
Author{2}{Email}#=%=#duckworthd@gmail.com
Author{2}{Affiliation}#=%=#Google Brain
Author{3}{Firstname}#=%=#Chris
Author{3}{Lastname}#=%=#Callison-Burch
Author{3}{Username}#=%=#ccb
Author{3}{Email}#=%=#ccb@cis.upenn.edu
Author{3}{Affiliation}#=%=#University of Pennsylvania
Author{4}{Firstname}#=%=#Douglas
Author{4}{Lastname}#=%=#Eck
Author{4}{Username}#=%=#douglaseck
Author{4}{Email}#=%=#deck@google.com
Author{4}{Affiliation}#=%=#Google Research

==========