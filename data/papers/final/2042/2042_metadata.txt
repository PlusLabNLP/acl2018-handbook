SubmissionNumber#=%=#2042
FinalPaperTitle#=%=#Structured Tuning for Semantic Role Labeling
ShortPaperTitle#=%=#
NumberOfPages#=%=#11
CopyrightSigned#=%=#Tao Li
JobTitle#==#
Organization#==#University of Utah
Abstract#==#Recent neural network-driven semantic role labeling (SRL) systems have shown impressive improvements in F1 scores. These improvements are due to expressive input representations, which, at least at the surface, are orthogonal to knowledge-rich constrained decoding mechanisms that helped linear SRL models. Introducing the benefits of structure to inform neural models presents a methodological challenge. In this paper, we present a structured tuning framework to improve models using softened constraints only at training time. Our framework leverages the expressiveness of neural networks and provides supervision with structured loss components. We start with a strong baseline (RoBERTa) to validate the impact of our approach, and show that our framework outperforms the baseline by learning to comply with declarative constraints. Additionally, our experiments with smaller training sizes show that we can achieve consistent improvements under low-resource scenarios.
Author{1}{Firstname}#=%=#Tao
Author{1}{Lastname}#=%=#Li
Author{1}{Username}#=%=#tli_nlp
Author{1}{Email}#=%=#tli@cs.utah.edu
Author{1}{Affiliation}#=%=#University of Utah
Author{2}{Firstname}#=%=#Parth Anand
Author{2}{Lastname}#=%=#Jawale
Author{2}{Username}#=%=#parthjawale
Author{2}{Email}#=%=#parth.jawale@colorado.edu
Author{2}{Affiliation}#=%=#University of Colorado Boulder
Author{3}{Firstname}#=%=#Martha
Author{3}{Lastname}#=%=#Palmer
Author{3}{Username}#=%=#martha.palmer
Author{3}{Email}#=%=#martha.palmer@colorado.edu
Author{3}{Affiliation}#=%=#University of Colorado
Author{4}{Firstname}#=%=#Vivek
Author{4}{Lastname}#=%=#Srikumar
Author{4}{Username}#=%=#vsrikum2
Author{4}{Email}#=%=#svivek@cs.utah.edu
Author{4}{Affiliation}#=%=#University of Utah

==========