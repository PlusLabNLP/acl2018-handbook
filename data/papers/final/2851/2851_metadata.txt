SubmissionNumber#=%=#2851
FinalPaperTitle#=%=#QuASE: Question-Answer Driven Sentence Encoding
ShortPaperTitle#=%=#
NumberOfPages#=%=#16
CopyrightSigned#=%=#Hangfeng He
JobTitle#==#
Organization#==#University of Pennsylvania, Philadelphia, PA 19104
Abstract#==#Question-answering (QA) data often encodes essential information in many facets. This paper studies a natural question: Can we get supervision from QA data for other tasks (typically, non-QA ones)? For example, {\em can we use QAMR (Michael et al., 2017) to improve named entity recognition?} We suggest that simply further pre-training BERT is often not the best option, and propose the {\em question-answer driven sentence encoding (QuASE)} framework. QuASE learns representations from QA data, using 
BERT or other state-of-the-art contextual language models. In particular, we observe the need to distinguish between two types of sentence encodings, depending on whether the target task is a single- or multi-sentence input; in both cases, the resulting encoding is shown to be an easy-to-use plugin for many downstream tasks. This work may point out an alternative way to supervise NLP tasks.
Author{1}{Firstname}#=%=#Hangfeng
Author{1}{Lastname}#=%=#He
Author{1}{Username}#=%=#hornhe
Author{1}{Email}#=%=#hangfeng@seas.upenn.edu
Author{1}{Affiliation}#=%=#University of Pennsylvania
Author{2}{Firstname}#=%=#Qiang
Author{2}{Lastname}#=%=#Ning
Author{2}{Username}#=%=#qiangning1990
Author{2}{Email}#=%=#qiangn@allenai.org
Author{2}{Affiliation}#=%=#Allen Institute for Artificial Intelligence
Author{3}{Firstname}#=%=#Dan
Author{3}{Lastname}#=%=#Roth
Author{3}{Username}#=%=#danr
Author{3}{Email}#=%=#danroth@seas.upenn.edu
Author{3}{Affiliation}#=%=#University of Pennsylvania

==========