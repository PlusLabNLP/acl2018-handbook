SubmissionNumber#=%=#1444
FinalPaperTitle#=%=#Data Manipulation: Towards Effective Instance Learning for Neural Dialogue Generation via Learning to Augment and Reweight
ShortPaperTitle#=%=#
NumberOfPages#=%=#10
CopyrightSigned#=%=#Hengyi Cai
JobTitle#==#
Organization#==#Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China
Abstract#==#Current state-of-the-art neural dialogue models learn from human conversations following the data-driven paradigm.
As such, a reliable training corpus is the crux of building a robust and well-behaved dialogue model.
However, due to the open-ended nature of human conversations, the quality of user-generated training data varies greatly, and effective training samples are typically insufficient while noisy samples frequently appear.
This impedes the learning of those data-driven neural dialogue models.
Therefore, effective dialogue learning requires not only more reliable learning samples, but also fewer noisy samples.
In this paper, we propose a data manipulation framework to proactively reshape the data distribution towards reliable samples by augmenting and highlighting effective learning samples as well as reducing the effect of inefficient samples simultaneously.
In particular, the data manipulation model selectively augments the training samples and assigns an importance weight to each instance to reform the training data. 
Note that, the proposed data manipulation framework is fully data-driven and learnable.
It not only manipulates training samples to optimize the dialogue generation model, but also learns to increase its manipulation skills through gradient descent with validation samples.
Extensive experiments show that our framework can improve the dialogue generation performance with respect to various automatic evaluation metrics and human judgments.
Author{1}{Firstname}#=%=#Hengyi
Author{1}{Lastname}#=%=#Cai
Author{1}{Username}#=%=#hengyicai
Author{1}{Email}#=%=#caihengyi@ict.ac.cn
Author{1}{Affiliation}#=%=#Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences
Author{2}{Firstname}#=%=#Hongshen
Author{2}{Lastname}#=%=#Chen
Author{2}{Username}#=%=#chenhongshen
Author{2}{Email}#=%=#ac@chenhongshen.com
Author{2}{Affiliation}#=%=#JD.com
Author{3}{Firstname}#=%=#Yonghao
Author{3}{Lastname}#=%=#Song
Author{3}{Username}#=%=#songyonghao
Author{3}{Email}#=%=#songyonghao@ict.ac.cn
Author{3}{Affiliation}#=%=#Institute of Computing Technology, Chinese Academy Of Sciences
Author{4}{Firstname}#=%=#Cheng
Author{4}{Lastname}#=%=#Zhang
Author{4}{Username}#=%=#zhch
Author{4}{Email}#=%=#zhangcheng@ict.ac.cn
Author{4}{Affiliation}#=%=#Institute of Computing Technology, Chinese Academy of Sciences
Author{5}{Firstname}#=%=#Xiaofang
Author{5}{Lastname}#=%=#Zhao
Author{5}{Username}#=%=#zhaoxiaofang
Author{5}{Email}#=%=#zhaoxf@ict.ac.cn
Author{5}{Affiliation}#=%=#Institute of Computing Technology, Academy of Science
Author{6}{Firstname}#=%=#Dawei
Author{6}{Lastname}#=%=#Yin
Author{6}{Username}#=%=#yindawei
Author{6}{Email}#=%=#yindawei@acm.org
Author{6}{Affiliation}#=%=#Baidu

==========