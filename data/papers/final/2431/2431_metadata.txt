SubmissionNumber#=%=#2431
FinalPaperTitle#=%=#Posterior Control of Blackbox Generation
ShortPaperTitle#=%=#
NumberOfPages#=%=#13
CopyrightSigned#=%=#Xiang Li
JobTitle#==#
Organization#==#Johns Hopkins University
Abstract#==#Text generation often requires high-precision output that obeys task-specific rules. This fine-grained control is difficult to enforce with off-the-shelf deep learning models. In this work, we consider augmenting neural generation models with discrete control states learned through a structured latent-variable approach. Under this formulation, task-specific knowledge can be encoded through a range of rich, posterior constraints that are effectively trained into the model. This approach allows users to ground internal model decisions based on prior knowledge, without sacrificing the representational power of neural generative models. Experiments consider applications of this approach for text generation. We find that this method improves over standard benchmarks, while also providing fine-grained control.
Author{1}{Firstname}#=%=#Xiang Lisa
Author{1}{Lastname}#=%=#Li
Author{1}{Username}#=%=#xli150
Author{1}{Email}#=%=#xli150@jhu.edu
Author{1}{Affiliation}#=%=#Johns Hopkins University
Author{2}{Firstname}#=%=#Alexander
Author{2}{Lastname}#=%=#Rush
Author{2}{Username}#=%=#srush
Author{2}{Email}#=%=#arush@cornell.edu
Author{2}{Affiliation}#=%=#Cornell University

==========