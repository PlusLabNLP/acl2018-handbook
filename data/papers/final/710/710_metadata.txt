SubmissionNumber#=%=#710
FinalPaperTitle#=%=#USR: An Unsupervised and Reference Free Evaluation Metric for Dialog Generation
ShortPaperTitle#=%=#
NumberOfPages#=%=#27
CopyrightSigned#=%=#Shikib Mehri
JobTitle#==#
Organization#==#Carnegie Mellon University
Abstract#==#The lack of meaningful automatic evaluation metrics for dialog has impeded open-domain dialog research. Standard language generation metrics have been shown to be ineffective for evaluating dialog models. To this end, this paper presents USR, an UnSupervised and Reference-free evaluation metric for dialog. USR is a reference-free metric that trains unsupervised models to measure several desirable qualities of dialog. USR is shown to strongly correlate with human judgment on both Topical-Chat (turn-level: 0.42, system-level: 1.0) and PersonaChat (turn-level: 0.48 and system-level: 1.0). USR additionally produces interpretable measures for several desirable properties of dialog.
Author{1}{Firstname}#=%=#Shikib
Author{1}{Lastname}#=%=#Mehri
Author{1}{Username}#=%=#shikibm
Author{1}{Email}#=%=#amehri@andrew.cmu.edu
Author{1}{Affiliation}#=%=#Carnegie Mellon University
Author{2}{Firstname}#=%=#Maxine
Author{2}{Lastname}#=%=#Eskenazi
Author{2}{Username}#=%=#max
Author{2}{Email}#=%=#max@cs.cmu.edu
Author{2}{Affiliation}#=%=#Carnegie Mellon University

==========