SubmissionNumber#=%=#1248
FinalPaperTitle#=%=#Learning Constraints for Structured Prediction Using Rectifier Networks
ShortPaperTitle#=%=#
NumberOfPages#=%=#16
CopyrightSigned#=%=#Xingyuan Pan
JobTitle#==#
Organization#==#University of Utah
Abstract#==#Various natural language processing tasks are structured prediction problems where outputs are constructed with multiple interdependent decisions. Past work has shown that domain knowledge, framed as constraints over the output space, can help improve predictive accuracy. However, designing good constraints often relies on domain expertise. In this paper, we study the problem of learning such constraints. We frame the problem as that of training a two-layer rectifier network to identify valid structures or substructures, and show a construction for converting a trained network into a system of linear constraints over the inference variables. Our experiments on several NLP tasks show that the learned constraints can improve the prediction accuracy, especially when the number of training examples is small.
Author{1}{Firstname}#=%=#Xingyuan
Author{1}{Lastname}#=%=#Pan
Author{1}{Username}#=%=#xingyuanp
Author{1}{Email}#=%=#xingyuanp@gmail.com
Author{1}{Affiliation}#=%=#University of Utah
Author{2}{Firstname}#=%=#Maitrey
Author{2}{Lastname}#=%=#Mehta
Author{2}{Username}#=%=#maitrey
Author{2}{Email}#=%=#maitreydams@gmail.com
Author{2}{Affiliation}#=%=#University of Utah
Author{3}{Firstname}#=%=#Vivek
Author{3}{Lastname}#=%=#Srikumar
Author{3}{Username}#=%=#vsrikum2
Author{3}{Email}#=%=#svivek@cs.utah.edu
Author{3}{Affiliation}#=%=#University of Utah

==========