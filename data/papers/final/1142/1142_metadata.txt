SubmissionNumber#=%=#1142
FinalPaperTitle#=%=#Recurrent Chunking Mechanisms for Long-Text Machine Reading Comprehension
ShortPaperTitle#=%=#
NumberOfPages#=%=#11
CopyrightSigned#=%=#Hongyu Gong
JobTitle#==#
Organization#==#Tencent AI Lab, Bellevue, WA, USA
Abstract#==#In this paper, we study machine reading comprehension (MRC) on long texts: where a model takes as inputs a lengthy document and a query, extracts a text span from the document as an answer. State-of-the-art models (e.g., BERT) tend to use a stack of transformer layers that are pre-trained from a large number of unlabeled language corpora to encode the joint contextual information of query and document. However, these transformer models can only take as input a fixed-length (e.g., $512$) text. To deal with even longer text inputs, previous approaches usually chunk them into \emph{equally-spaced} segments and predict answers based on each segment independently without considering the information from other segments. As a result, they may form segments that fail to cover complete answers or retain insufficient contexts around the correct answer required for question answering. Moreover, they are less capable of answering questions that need cross-segment information.

We propose to let a model learn to chunk in a more flexible way via reinforcement learning: a model can decide the next segment that it wants to process in either direction. We also apply recurrent mechanisms to enable information to flow across segments. Experiments on three MRC tasks -- CoQA, QuAC, and TriviaQA -- demonstrate the effectiveness of our proposed recurrent chunking mechanisms: we can obtain segments that are more likely to contain complete answers and at the same time provide sufficient contexts around the ground truth answers for better predictions.
Author{1}{Firstname}#=%=#Hongyu
Author{1}{Lastname}#=%=#Gong
Author{1}{Username}#=%=#hongyugong
Author{1}{Email}#=%=#hongyugong6@gmail.com
Author{1}{Affiliation}#=%=#University of Illinois at Urbana-Champaign
Author{2}{Firstname}#=%=#Yelong
Author{2}{Lastname}#=%=#Shen
Author{2}{Username}#=%=#shenyelong
Author{2}{Email}#=%=#shengyelong@gmail.com
Author{2}{Affiliation}#=%=#Tencent AI
Author{3}{Firstname}#=%=#Dian
Author{3}{Lastname}#=%=#Yu
Author{3}{Username}#=%=#dian
Author{3}{Email}#=%=#yudiandoris@gmail.com
Author{3}{Affiliation}#=%=#Tencent AI Lab
Author{4}{Firstname}#=%=#Jianshu
Author{4}{Lastname}#=%=#Chen
Author{4}{Username}#=%=#chenjianshu
Author{4}{Email}#=%=#chenjianshu@gmail.com
Author{4}{Affiliation}#=%=#Tencent AI Lab
Author{5}{Firstname}#=%=#Dong
Author{5}{Lastname}#=%=#Yu
Author{5}{Username}#=%=#dongyu
Author{5}{Email}#=%=#dongyu@ieee.org
Author{5}{Affiliation}#=%=#Tencent AI Lab

==========