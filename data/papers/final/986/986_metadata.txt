SubmissionNumber#=%=#986
FinalPaperTitle#=%=#Masking Actor Information Leads to Fairer Political Claims Detection
ShortPaperTitle#=%=#
NumberOfPages#=%=#7
CopyrightSigned#=%=#Erenay Dayanik
JobTitle#==#
Organization#==#IMS, University of Stuttgart
Abstract#==#A central concern in Computational Social Sciences (CSS) is fairness: where the role of NLP is to scale up text analysis to large corpora, the quality of automatic analyses should be as independent as possible of textual properties. We analyze the performance of a state-of-the-art neural model on the task of political claims detection  (i.e., the identification of forward-looking statements made by political actors) and identify a strong frequency bias:  claims made by frequent actors are recognized better. We propose two simple debiasing methods which mask proper names and pronouns during training of the model, thus removing personal information bias.  We find that (a) these methods significantly decrease frequency bias while keeping the overall performance stable; and  (b) the resulting models improve when evaluated in an out-of-domain setting.
Author{1}{Firstname}#=%=#Erenay
Author{1}{Lastname}#=%=#Dayanik
Author{1}{Username}#=%=#erenaydayanik
Author{1}{Email}#=%=#erenay.dayanik@ims.uni-stuttgart.de
Author{1}{Affiliation}#=%=#Graduate Student at IMS - University of Stuttgart
Author{2}{Firstname}#=%=#Sebastian
Author{2}{Lastname}#=%=#Pad√≥
Author{2}{Username}#=%=#pado
Author{2}{Email}#=%=#pado@ims.uni-stuttgart.de
Author{2}{Affiliation}#=%=#Stuttgart University

==========