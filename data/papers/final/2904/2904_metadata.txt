SubmissionNumber#=%=#2904
FinalPaperTitle#=%=#Relation Extraction with Explanation
ShortPaperTitle#=%=#
NumberOfPages#=%=#7
CopyrightSigned#=%=#Hamed Shahbazi
JobTitle#==#PhD student, research and teaching assistant
Organization#==#School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR, USA
Abstract#==#Recent neural models for relation extraction with distant supervision alleviate the impact of irrelevant sentences in a bag by learning importance weights for the sentences. Efforts thus far have focused on improving extraction accuracy but little is known about their explanability. In this work we annotate a test set with ground-truth sentence-level explanations to evaluate the quality of explanations afforded by the relation extraction models. We demonstrate that replacing the entity mentions in the sentences with their fine-grained entity types not only enhances extraction accuracy but also improves explanation. We also propose to automatically generate ``distractor'' sentences to augment the bags and train the model to ignore the distractors. Evaluations on the widely used FB-NYT dataset show that our methods achieve new state-of-the-art accuracy while improving model explanability.
Author{1}{Firstname}#=%=#Hamed
Author{1}{Lastname}#=%=#Shahbazi
Author{1}{Username}#=%=#hshahbazi
Author{1}{Email}#=%=#shahbazh@oregonstate.edu
Author{1}{Affiliation}#=%=#Oregon State University
Author{2}{Firstname}#=%=#Xiaoli
Author{2}{Lastname}#=%=#Fern
Author{2}{Username}#=%=#xfern
Author{2}{Email}#=%=#xfern@oregonstate.edu
Author{2}{Affiliation}#=%=#Oregon State University
Author{3}{Firstname}#=%=#Reza
Author{3}{Lastname}#=%=#Ghaeini
Author{3}{Username}#=%=#rezaghaeini
Author{3}{Email}#=%=#ghaeinim@oregonstate.edu
Author{3}{Affiliation}#=%=#Oregon State University
Author{4}{Firstname}#=%=#Prasad
Author{4}{Lastname}#=%=#Tadepalli
Author{4}{Username}#=%=#tadepalli
Author{4}{Email}#=%=#tadepall@eecs.oregonstate.edu
Author{4}{Affiliation}#=%=#Oregon State University

==========