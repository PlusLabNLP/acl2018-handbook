SubmissionNumber#=%=#13
FinalPaperTitle#=%=#Demoting Racial Bias in Hate Speech Detection
ShortPaperTitle#=%=#
NumberOfPages#=%=#8
CopyrightSigned#=%=#
JobTitle#==#
Organization#==#Mengzhou Xia, CMU
Abstract#==#In the task of hate speech detection, there exists a high correlation between African American English (AAE) and annotators' perceptions of toxicity in current datasets. This bias in annotated training data and the tendency of machine learning models to amplify it cause AAE text to often be mislabeled as abusive/offensive/hate speech (high false positive rate) by current hate speech classifiers. Here, we use adversarial training to mitigate this bias. Experimental results on one hate speech dataset and one AAE dataset suggest that our method is able to reduce the false positive rate for AAE text with only a minimal compromise on the performance of hate speech classification.
Author{1}{Firstname}#=%=#Mengzhou
Author{1}{Lastname}#=%=#Xia
Author{1}{Username}#=%=#xiamengzhou
Author{1}{Email}#=%=#mengzhox@andrew.cmu.edu
Author{1}{Affiliation}#=%=#Carnegie Mellon University
Author{2}{Firstname}#=%=#Anjalie
Author{2}{Lastname}#=%=#Field
Author{2}{Username}#=%=#anjalief
Author{2}{Email}#=%=#anjalief@gmail.com
Author{2}{Affiliation}#=%=#Carnegie-Mellon University
Author{3}{Firstname}#=%=#Yulia
Author{3}{Lastname}#=%=#Tsvetkov
Author{3}{Username}#=%=#yulia.tsvetkov
Author{3}{Email}#=%=#ytsvetko@cs.cmu.edu
Author{3}{Affiliation}#=%=#Carnegie Mellon University

==========