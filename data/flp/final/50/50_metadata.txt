SubmissionNumber#=%=#50
FinalPaperTitle#=%=#Transformer-based Context-aware Sarcasm Detection in Conversation Threads from Social Media
ShortPaperTitle#=%=#
NumberOfPages#=%=#5
CopyrightSigned#=%=#Xiangjue Dong
JobTitle#==#
Organization#==#Emory University, Atlanta, GA, USA
Abstract#==#We present a transformer-based sarcasm detection model that accounts for the context from the entire conversation thread for more robust predictions. Our model uses deep transformer layers to perform multi-head attentions among the target utterance and the relevant context in the thread. The context-aware models are evaluated on two datasets from social media, Twitter and Reddit, and show 3.1% and 7.0% improvements over their baselines. Our best models give the F1-scores of 79.0% and 75.0% for the Twitter and Reddit datasets respectively, becoming one of the highest performing systems among 36 participants in this shared task.
Author{1}{Firstname}#=%=#Xiangjue
Author{1}{Lastname}#=%=#Dong
Author{1}{Username}#=%=#dxj
Author{1}{Email}#=%=#xdong57@emory.edu
Author{1}{Affiliation}#=%=#Emory University
Author{2}{Firstname}#=%=#Changmao
Author{2}{Lastname}#=%=#Li
Author{2}{Username}#=%=#changmao.li
Author{2}{Email}#=%=#changmao.li@emory.edu
Author{2}{Affiliation}#=%=#Emory University
Author{3}{Firstname}#=%=#Jinho D.
Author{3}{Lastname}#=%=#Choi
Author{3}{Username}#=%=#jdchoi77
Author{3}{Email}#=%=#jinho.choi@emory.edu
Author{3}{Affiliation}#=%=#Emory University

==========