SubmissionNumber#=%=#43
FinalPaperTitle#=%=#{D}etecting {S}arcasm in {C}onversation {C}ontext {U}sing {T}ransformer-{B}ased {M}odels
ShortPaperTitle#=%=#
NumberOfPages#=%=#6
CopyrightSigned#=%=#Adithya Avvaru
JobTitle#==#
Organization#==#IIIT Hyderabad, Gachibowli, Hyderabad, Telangana State, India
Abstract#==#Sarcasm detection, regarded as one of the sub-problems of sentiment analysis, is a very typical task because the introduction of sarcastic words can flip the sentiment of the sentence
itself. To date, many research works revolve around detecting sarcasm in one single
sentence and there is very limited research to detect sarcasm resulting from multiple sentences. Current models used Long Short Term Memory (LSTM) variants with or without attention to detect sarcasm in conversations. We showed that the models using state-of-the-art Bidirectional Encoder Representations from Transformers (BERT), to capture syntactic and semantic information across conversation sentences, performed better than the current models. Based on the data analysis, we estimated that the number of sentences in the conversation that can contribute to the sarcasm and the results agrees to this estimation. We also perform a comparative study of our different versions of BERT-based model with other variants of LSTM model and XLNet (both using the estimated number of conversation sentences) and find out that BERT-based models outperformed them.
Author{1}{Firstname}#=%=#Adithya
Author{1}{Lastname}#=%=#Avvaru
Author{1}{Username}#=%=#adithya604
Author{1}{Email}#=%=#adithya.avvaru@students.iiit.ac.in
Author{1}{Affiliation}#=%=#Teradata
Author{2}{Firstname}#=%=#Sanath
Author{2}{Lastname}#=%=#Vobilisetty
Author{2}{Username}#=%=#sanath97
Author{2}{Email}#=%=#sanath.vobilisetty@teradata.com
Author{2}{Affiliation}#=%=#Teradata
Author{3}{Firstname}#=%=#Radhika
Author{3}{Lastname}#=%=#Mamidi
Author{3}{Username}#=%=#radhika
Author{3}{Email}#=%=#radhika.mamidi@iiit.ac.in
Author{3}{Affiliation}#=%=#IIIT Hyderabad

==========