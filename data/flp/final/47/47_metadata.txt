SubmissionNumber#=%=#47
FinalPaperTitle#=%=#Go Figure! Multi-task transformer-based architecture for metaphor detection using idioms: ETS team in 2020 metaphor shared task
ShortPaperTitle#=%=#
NumberOfPages#=%=#9
CopyrightSigned#=%=#Chee Wee Leong
JobTitle#==#Senior Research Engineer
Organization#==#Educational Testing Service, 660 Rosedale Rd, Princeton, NJ 08540, USA
Abstract#==#This paper describes the ETS entry to the 2020 Metaphor Detection shared task. Our contribution consists of a sequence of experiments using BERT, starting with a baseline, strengthening it by spell-correcting the TOEFL corpus, followed by a multi-task learning setting, where one of the tasks is the token-level metaphor classification as per the shared task, while the other is meant to provide additional training that we hypothesized to be relevant to the main task. In one case, out-of-domain data manually annotated for metaphor is used for the auxiliary task; in the other case, in-domain data automatically annotated for idioms is used for the auxiliary task. Both multi-task experiments yield promising results.
Author{1}{Firstname}#=%=#Xianyang
Author{1}{Lastname}#=%=#Chen
Author{1}{Email}#=%=#XCHEN002@ets.org
Author{1}{Affiliation}#=%=#Educational Testing Service
Author{2}{Firstname}#=%=#Chee Wee (Ben)
Author{2}{Lastname}#=%=#Leong
Author{2}{Username}#=%=#lcwben
Author{2}{Email}#=%=#cleong@ets.org
Author{2}{Affiliation}#=%=#Educational Testing Service
Author{3}{Firstname}#=%=#Michael
Author{3}{Lastname}#=%=#Flor
Author{3}{Email}#=%=#mflor@ets.org
Author{3}{Affiliation}#=%=#Educational Testing Service
Author{4}{Firstname}#=%=#Beata
Author{4}{Lastname}#=%=#Beigman Klebanov
Author{4}{Username}#=%=#bbeigmanklebanov
Author{4}{Email}#=%=#bbeigmanklebanov@ets.org
Author{4}{Affiliation}#=%=#Educational Testing Service

==========