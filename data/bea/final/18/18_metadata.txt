SubmissionNumber#=%=#18
FinalPaperTitle#=%=#CIMA: A Large Open Access Dialogue Dataset for Tutoring
ShortPaperTitle#=%=#
NumberOfPages#=%=#13
CopyrightSigned#=%=#Katherine Stasaski
JobTitle#==#Ph.D. Student
Organization#==#UC Berkeley, 2626 Hearst Ave, Berkeley, CA 94720
Abstract#==#One-to-one tutoring is often an effective means to help students learn, and recent experiments with neural conversation systems are promising.  However, large open datasets of tutoring conversations are lacking.  To remedy this, we propose a novel asynchronous method for collecting tutoring dialogue via crowdworkers that is both amenable to the needs of deep learning algorithms and reflective of pedagogical concerns.    In this approach, extended conversations are obtained between crowdworkers role-playing as both students and tutors.  The CIMA collection, which we make publicly available, is novel in that students are exposed to overlapping grounded concepts between exercises and multiple relevant tutoring responses are collected for the same input.

CIMA contains several compelling properties from an educational perspective: student role-players complete exercises in fewer turns during the course of the conversation and tutor players adopt strategies that conform with some educational conversational norms, such as providing hints versus asking questions in appropriate contexts.  The dataset enables a model to be trained to generate the next tutoring utterance in a conversation, conditioned on a provided action strategy.
Author{1}{Firstname}#=%=#Katherine
Author{1}{Lastname}#=%=#Stasaski
Author{1}{Username}#=%=#kstasaski
Author{1}{Email}#=%=#katie_stasaski@berkeley.edu
Author{1}{Affiliation}#=%=#University of California at Berkeley
Author{2}{Firstname}#=%=#Kimberly
Author{2}{Lastname}#=%=#Kao
Author{2}{Email}#=%=#kimkao957@gmail.com
Author{2}{Affiliation}#=%=#Facebook
Author{3}{Firstname}#=%=#Marti A.
Author{3}{Lastname}#=%=#Hearst
Author{3}{Username}#=%=#hearst
Author{3}{Email}#=%=#hearst@berkeley.edu
Author{3}{Affiliation}#=%=#UC Berkeley

==========