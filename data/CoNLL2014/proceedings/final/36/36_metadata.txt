SubmissionNumber#=%=#36
FinalPaperTitle#=%=#Linguistic Regularities in Sparse and Explicit Word Representations
ShortPaperTitle#=%=#Linguistic Regularities in Sparse and Explicit Word Representations
NumberOfPages#=%=#10
CopyrightSigned#=%=#Omer Levy
JobTitle#==#
Organization#==#Bar-Ilan University
Ramat-Gan, Israel
Abstract#==#Recent work has shown that neural-embedded word representations
capture many relational similarities, which can be recovered by
means of vector arithmetic in the embedded space.
We show that Mikolov et al.'s method of first adding and subtracting
word vectors, and then searching for a word similar to the result, is 
equivalent to searching for a word that maximizes a linear combination
of three pairwise word similarities.
Based on this observation, we suggest an improved method of
recovering relational similarities, improving the state-of-the-art results on
two recent word-analogy datasets.
Moreover, we demonstrate that analogy recovery is not restricted
to neural word embeddings, and that a similar amount of relational
similarities can be recovered from traditional distributional word
representations.
Author{1}{Firstname}#=%=#Omer
Author{1}{Lastname}#=%=#Levy
Author{1}{Email}#=%=#omerlevy@cs.biu.ac.il
Author{1}{Affiliation}#=%=#Bar-Ilan University
Author{2}{Firstname}#=%=#Yoav
Author{2}{Lastname}#=%=#Goldberg
Author{2}{Email}#=%=#yoav.goldberg@gmail.com
Author{2}{Affiliation}#=%=#Bar Ilan University

==========