SubmissionNumber#=%=#70
FinalPaperTitle#=%=#Distributed Word Representation Learning for Cross-Lingual Dependency Parsing
ShortPaperTitle#=%=#Distributed Word Representation Learning for Cross-Lingual Dependency Parsing
NumberOfPages#=%=#11
CopyrightSigned#=%=#Yuhong Guo
JobTitle#==#
Organization#==#
Abstract#==#This paper proposes to learn language-independent word representations to
address cross-lingual dependency parsing, which aims to predict the dependency
parsing trees for sentences in the target language by training a dependency
parser with labeled sentences from a source language. We Ô¨Årst combine all
sentences from both languages to induce real-valued distributed representation
of words under a deep neural network architecture, which is expected to capture
semantic similarities of words not only within the same language but also
across different languages. We then use the induced interlingual word
representation as augmenting features to train a delexicalized dependency
parser on labeled sentences in the source language and apply it to the target
sentences. To investigate the effectiveness of the proposed technique,
extensive experiments are conducted on cross-lingual dependency parsing tasks
with nine different languages. The experimental results demonstrate the
superior cross-lingual generalizability of the word representation induced by
the proposed approach, comparing to alternative comparison methods.
Author{1}{Firstname}#=%=#Min
Author{1}{Lastname}#=%=#Xiao
Author{1}{Email}#=%=#minxiao@temple.edu
Author{1}{Affiliation}#=%=#Temple University
Author{2}{Firstname}#=%=#Yuhong
Author{2}{Lastname}#=%=#Guo
Author{2}{Email}#=%=#yuhong@temple.edu
Author{2}{Affiliation}#=%=#Temple University

==========