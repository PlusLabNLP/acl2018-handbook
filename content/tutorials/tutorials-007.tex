\begin{tutorial}{Deep Reinforcement Learning for NLP}
  {tutorial-039}
  {\daydateyear, \tutorialafternoontime}
  {\TutLocG}

\end{tutorial}


Many Natural Language Processing (NLP) tasks (including generation, language
grounding, reasoning, information extraction, coreference resolution, and
dialog) can be formulated as deep reinforcement learning (DRL) problems.
However, since language is often discrete and the space for all sentences is
infinite, there are many challenges for formulating reinforcement learning
problems of NLP tasks. In this tutorial, we provide a gentle introduction to
the foundation of deep reinforcement learning, as well as some practical DRL
solutions in NLP. We describe recent advances in designing deep reinforcement
learning for NLP, with a special focus on generation, dialogue, and information
extraction. Finally, we discuss why they succeed, and when they may fail,
aiming at providing some practical advice about deep reinforcement learning for
solving real-world NLP problems.

\vspace{2ex}\centerline{\rule{.5\linewidth}{.5pt}}\vspace{2ex}
\setlength{\parskip}{1ex}\setlength{\parindent}{0ex}



{\bfseries William Yang Wang} is an Assistant Professor at the Department
of Computer Science, University of California,
Santa Barbara. He received his PhD from
School of Computer Science, Carnegie Mellon University.
He focuses on information extraction and he
is the faculty author of DeepPathâ€”the first deep reinforcement
learning system for multi-hop reasoning.
He has published more than 50 papers at leading conferences
and journals including ACL, EMNLP, NAACL,
CVPR, COLING, IJCAI, CIKM, ICWSM, SIGDIAL,
IJCNLP, INTERSPEECH, ICASSP, ASRU, SLT, Machine
Learning, and Computer Speech \& Language,
and he has received paper awards and honors from
CIKM, ASRU, and EMNLP.Website: \url{http://www.
cs.ucsb.edu/~william/}.

{\bfseries Jiwei Li} recently spent three years and received his
PhD in Computer Science from Stanford University.
His research interests are deep learning and dialogue.
He is the most prolific NLP/ML first author during
2012-2016, and the lead author of the first study in deep
reinforcement learning for dialogue generation. He is
the recipient of a Facebook Fellowship in 2015. Website:
\url{https://web.stanford.edu/~jiweil/}.

{\bfseries Xiaodong He} is the Deputy Managing Director of JD
AI Research and Head of the Deep learning, NLP
and Speech Lab, and a Technical Vice President of
JD.com. He is also an Affiliate Professor at the University
of Washington (Seattle), serves in doctoral supervisory
committees. Before joining JD.com, He was
with Microsoft for about 15 years, served as Principal
Researcher and Research Manager of the DLTC
at Microsoft Research, Redmond. His research interests
are mainly in artificial intelligence areas including
deep learning, natural language, computer vision,
speech, information retrieval, and knowledge representation.
He has published more than 100 papers in ACL,
EMNLP, NAACL, CVPR, SIGIR, WWW, CIKM, NIPS,
ICLR, ICASSP, Proc. IEEE, IEEE TASLP, IEEE SPM,
and other venues. He received several awards including
the Outstanding Paper Award at ACL 2015. Website:
\url{http://air.jd.com/people2.html}.




