\begin{bio}
\small
{\bfseries William Yang Wang} 

{\bfseries Jiwei Li}

{\bfseries Xiaodong He}

\end{bio}

\begin{tutorial}{Deep Reinforcement Learning for NLP}
  {tutorial-039}
  {\daydateyear, \tutorialafternoontime}
  {\TutLocG}

Many Natural Language Processing (NLP) tasks (including generation, language grounding, reasoning, information extraction, coreference resolution, and dialog) can be formulated as Deep Reinforcement Learning (DRL) problems. However, since language is often discrete and the space for all sentences is infinite, there are many challenges for formulating reinforcement learning problems of NLP tasks. In this tutorial, we provide a gentle introduction to the foundation of Deep Reinforcement Learning, as well as some practical DRL solutions in NLP. We will show how DRL is different from traditional learning settings in NLP, and different ways of interpreting DRL models. We then introduce recent advances in designing deep reinforcement learning for NLP, with a special focus on generation, dialogue, and information extraction. Finally, we discuss the challenges going forward, including why they succeed, and when they may fail, aiming at providing some practical advice about deep reinforcement learning for solving real-world NLP problems.

\end{tutorial}
