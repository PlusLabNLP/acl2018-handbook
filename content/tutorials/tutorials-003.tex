
\begin{tutorial}
  {}
  {tutorials-003}
  {}
  {\TutLocA}
  {\TutLevelA}
\end{tutorial}

  %{\daydateyear, \tutorialtimea \ and \tutorialtimeb \\\tutorialtimezone}

\tutorialabstract{}{}{}{}{tutorials-003}

\vspace{2ex}\centerline{\rule{.5\linewidth}{.5pt}}\vspace{2ex}
\setlength{\parskip}{1ex}\setlength{\parindent}{0ex}

% \begin{bio}

{\small

{\bfseries Yonatan Belinkov}, Postdoctoral Fellow, Harvard
University and MIT

email: {\tt belinkov@seas.harvard.edu} \\
website: {\tt http://people.csail.mit.edu/belinkov} \\
Yonatan Belinkov is a Postdoctoral Fellow at
the Harvard School of Engineering and Applied
Sciences (SEAS) and the MIT Computer Science
and Artificial Intelligence Laboratory (CSAIL).
His research interests are in interpretability and
robustness of neural models of language. He
has done previous work in machine translation,
speech recognition, community question answering, and syntactic parsing. His research has been published at ACL, EMNLP, NAACL, CL, TACL,
ICLR, and NeurIPS. His PhD dissertation at MIT
analyzed internal language representations in deep
learning models. He co-organized or co-organizes
BlackboxNLP 2019, BlackboxNLP 2020, and the
WMT 2019 machine translation robustness task,
and serves as an area chair for the analysis and
interpretability track at ACL and EMNLP 2020.

{\bfseries Sebastian Gehrmann}, Research Scientist,
Google AI

email: {\tt gehrmann@google.com}  \\
website: {\tt http://sebastiangehrmann.com} \\
Sebastian is research scientist at Google AI. He
received his PhD in 2020 from Harvard University. His research focuses on the development and
evaluation of controllable and interpretable models for language generation. By applying methods
from human-computer interaction and visualization to problems in NLP, he develops interactive
interfaces that help with the interpretation and
explanation of neural networks. His research
has been published at ACL, NAACL, EMNLP,
CHI, and IEEE VIS. He received an honorable
mention at VAST 2018 and was nominated for
ACL best demo 2019 for his work on interactive
visualization tools. He co-organized INLG 2019
and served as an area chair in summarization for
ACL 2020.

{\bfseries Ellie Pavlick}, Assistant Professor of Computer
Science, Brown University

email: {\tt ellie\_pavlick@brown.edu}  \\
website: {\tt http://cs.brown.edu/people/epavlick} \\
Ellie Pavlick is an Assistant Professor at Brown
University and a Research Scientist at Google.
She received her PhD in 2017 with her thesis on
modeling compositional lexical semantics. Her
current work focuses on computational models of
semantics and pragmatics, with a focus on building cognitively-plausible representations. Her recent work has focused on “probing” distributional
models in order to better understand the linguistic
phenomena that are and are not encoded “for free”
via language modelling. Her work has been published at ACL, NAACL, EMNLP, TACL, *SEM,
and ICLR, including two best paper awards at *SEM 2016 and 2019. Ellie co-organized the 2018
JSALT summer workshop on building and evaluating general-purpose sentence representations.
She also served as area chair for ACL’s sentencelevel semantics track.
  
}
% \end{bio}