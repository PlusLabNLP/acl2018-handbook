
\begin{tutorial}
  {}
  {tutorials-014}
  {\daydateyear, \tutorialtimea \ and \tutorialtimeb \\\tutorialtimezone}
  {\TutLocG}
  {\TutLevelG}
\end{tutorial}


\tutorialabstract{}{}{}{}{tutorials-014}

\vspace{2ex}\centerline{\rule{.5\linewidth}{.5pt}}\vspace{2ex}
\setlength{\parskip}{1ex}\setlength{\parindent}{0ex}

{\small

{\bfseries Emily M. Bender},
University of Washington\\
{\tt ebender@uw.edu}\\
{\tt faculty.washington.edu/ebender}\\
Emily M. Bender is a Professor of Linguistics
and Adjunct Professor of Computer Science and
Engineering at the University of Washington. Her
research interests include computational semantics, grammar engineering, computational linguistic typology, and ethics in NLP. She is the Faculty
Director of UW’s Professional Masters in Computational Linguistics (CLMS) and has been engaged
with integrating ethics into the CLMS curriculum
since 2016. She co-organized the first EthNLP
workshop. Her first publication in this area is the
TACL paper “Data Statements for NLP: Toward
Mitigating System Bias and Enabling Better Science” (Bender and Friedman, 2018) and she has
been an invited speaker at workshops and panels
related to ethics and NLP (or AI more broadly)
at the Taskar Memorial Event (UW, March 2018),
The Future of Artificial Intelligence: Language,
Ethics, Technology (Cambridge, March 2019),
West Coast NLP (Facebook, September 2019),
Machine Learning Competitions for All (NeurIPS,
December 2019) and AAAS (Seattle, February
2020).

{\bfseries Xanda Schofield},
Harvey Mudd College\\
{\tt xanda@cs.hmc.edu}\\
{\tt www.cs.hmc.edu/~xanda}\\
Xanda Schofield is an Assistant Professor of
Computer Science at Harvey Mudd College. Her
work focuses on the practical aspects of using distributional semantic models for analysis of realworld datasets, with problems ranging from understanding the consequences of data pre-processing
on model inference (Schofield and Mimno, 2016;
Schofield et al., 2017) to enforcing text privacy
for these models (Schein et al., 2018). She also
is interested in pedagogy at this intersection, having co-developed a Text Mining for History and
Literature course at Cornell University with David
Mimno. She is currently focusing pedagogical efforts on how to introduce considerations of ethics
and bias into other courses such as Algorithms.

{\bfseries Dirk Hovy},
Bocconi University\\
{\tt dirk.hovy@unibocconi.it}\\
{\tt www.dirkhovy.com}\\
Dirk Hovy is an Associate Professor of Computer Science in the Department of Marketing at
Bocconi University in Milan, Italy. His research
focuses on how social dimensions influence language and in turn NLP models, as well as on
questions of bias and fairness. He strives to integrate sociolinguistic knowledge into NLP models to counteract demographic bias. Dirk has written on ethics and bias in NLP (Hovy and Spruit,
2016), co-organized two editions of the EthNLP
workshops and one of the abusive language workshop, and was an invited speaker on panels on
ethics at NAACL 2018 and SLT 2018. He is
teaching a related tutorial (on ethic

}