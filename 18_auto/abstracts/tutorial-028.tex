Semantic parsers translate natural language utterances        into machine-executable  logical  forms  or programs,  and  are  thus  key components  in        natural language  understanding  systems.   Semantic parsing is  a  well-established  research area, with application  in  areas  such  as question  answering, instruction  following, voice assistants, and code generation.  In the last two years, the models used for semantic  parsing have changed  dramatically,with the introduction of neural methods that allow us to rethink many of the previous assumptions underlying semantic parsing. Traditionally,        the  executable  formalisms  and models  used  in  semantic parsing  research  have been heavily reliant on notions of formal semantics in linguistics, such as Î»-calculus generated by a CCG parser.  However, recent work with neural encoder-decoder semantic parsers allow for more accessible formalisms, such as standard programming  languages,  and  NMT-style  models that  are much        more  approachable  to        a  broader  NLP  audience.   We will present an overview of modern neural methods for semantic parsing and how they have changed semantic parsing research.
