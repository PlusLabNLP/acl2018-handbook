We investigate data driven natural lan- guage generation under the constraints that all words must come from a fixed vo- cabulary and a specified word must ap- pear in the generated sentence, motivated by the possibility for automatic genera- tion of language education exercises. We present fast and accurate approximations to the ideal rejection samplers for these constraints and compare various sentence level generative language models. Our best systems produce output that is with high frequency both novel and error free, which we validate with human and auto- matic evaluations.
