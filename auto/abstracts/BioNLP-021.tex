An up-to-date problem list is useful for assessing a patient's current clinical status. Natural language processing can help maintain an accurate problem list. For instance, a patient problem list from a clinical document can be derived from individual problem mentions within the clinical document once these mentions are mapped to a standard vocabulary. In order to develop and evaluate accurate document-level inference engines for this task, a patient problem list could be generated using a standard vocabulary. Adequate coverage by standard vocabularies is important for supporting a clear representation of the patient problem concepts described in the texts and for interoperability between clinical systems within and outside the care facilities. In this pilot study, we report the reliability of domain expert generation of a patient problem list from a variety of clinical texts and evaluate the coverage of annotated patient problems against SNOMED CT and SNOMED Clinical Observation Recording and Encoding (CORE) Problem List. Across report types, we learned that patient problems can be annotated with agreement ranging from 77.1\% to 89.6\% F1-score and mapped to the CORE with moderate coverage ranging from 45\%-67\% of patient problems.
