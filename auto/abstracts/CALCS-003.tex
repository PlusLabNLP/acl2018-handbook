Speakers in multilingual communities often switch between or mix multiple languages in the same conversation.   Automatic Speech Recognition (ASR) of code-switched speech faces many challenges including the influence of phones of  different languages on each other. This paper shows evidence that phone sharing between languages improves the Acoustic Model performance for Hindi-English code-switched speech. We compare baseline system built with separate phones for Hindi and English with systems where the phones were manually merged based on linguistic knowledge. Encouraged by the improved  ASR performance after manually merging the phones, we further investigate multiple data-driven methods to identify phones to be merged across  the languages. We show detailed analysis of automatic phone merging in this language pair and the impact it has on individual phone accuracies and WER. Though the best performance gain of 1.2\% WER was observed with manually merged phones, we show experimentally that the manual phone merge is not optimal.
