We   describe   our   experiences   in   using  an  open  domain  question  answering model  (Chen  et  al.,  2017)  to  evaluate  an out-of-domain  QA  task  of  assisting  in analyzing  privacy  policies  of  companies. Specifically,  Relevant  CI  Parameters  Extractor  (RECIPE)  seeks  to  answer  questions  posed  by  the  theory  of  contextual integrity  (CI)  regarding  the  information flows described in the privacy statements. These  questions  have  a  simple  syntactic structure  and  the  answers  are  factoids  or descriptive in nature. The model achieved an F1 score of 72.33, but we noticed that combining the results of this model with a neural dependency parser based approach yields  a  significantly  higher  F1  score  of 92.35  compared  to  manual  annotations. This indicates that future work which in-corporates signals from parsing like NLP tasks more explicitly can generalize better on out-of-domain tasks.
