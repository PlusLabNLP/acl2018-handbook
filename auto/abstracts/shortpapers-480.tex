We present several alternative asymmetric models based on Tversky (1977) and show how they improve correlations with human similarity judgments and improve nearest neighbor discovery for both very frequent and very rare words.  We attribute this to a principle discovered by Tversky, that in comparing sparse and rich representations, the feature weights may be tipped in favor of recalling the features of the sparser representation, since improvement on our two tasks can be traced to improved performance when comparing mid-frequency and frequent words.
